{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wojXqpbzAMdD"
   },
   "source": [
    "In questo notebook le reti neurali vengono utilizzate per trovare e analizzare i pattern piÃ¹ complessi. Basta eseguire Runtime->esegui tutte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1613220334480,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "oQNamwhVsrbd",
    "outputId": "886112dd-e4e1-4cf8-935a-59af0e4ba002"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sng4-l9sAfUf"
   },
   "source": [
    "IMPORTANTE: queste versioni non vanno cambiate. Versioni successive di Tensorflow non fanno girare il codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118414,
     "status": "ok",
     "timestamp": 1613220451924,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "otMuOedo8nnQ",
    "outputId": "cb678c37-e5ca-4df5-c427-909f0e4960e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install q keras==2.3.1\n",
    "# !pip install q tensorflow==2.2.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 118415,
     "status": "ok",
     "timestamp": 1613220451929,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "HJHVz2mYvGla",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def background_thumbnail(template, modality, thumbnail_size=(200,200)):\n",
    "    foreground = Image.fromarray(template).convert(modality)\n",
    "    background = Image.new(modality, thumbnail_size, \"white\")\n",
    "    foreground.thumbnail(thumbnail_size)\n",
    "    (w, h) = foreground.size\n",
    "    upper_left=(int((thumbnail_size[0] - w) / 2), int((thumbnail_size[1] - h) / 2))\n",
    "    background.paste(foreground, upper_left)\n",
    "    return np.array(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 119333,
     "status": "ok",
     "timestamp": 1613220452852,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "kir95NDuvfuY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def maxDeviationThresh(hist):\n",
    "    maximum = max(hist)\n",
    "    index_max = list(hist).index(maximum)\n",
    "    index_min = 0\n",
    "    for i in range(0, index_max):\n",
    "        if not hist[i] and hist[i+1]:\n",
    "            index_min = i\n",
    "            break\n",
    "    \n",
    "    distances = []\n",
    "    x1 = index_min\n",
    "    y1 = hist[index_min]\n",
    "    x2 = index_max\n",
    "    y2 = hist[index_max]\n",
    "    for i in range(index_min + 1, index_max):\n",
    "        x0 = i\n",
    "        y0 = hist[i]\n",
    "        distance = np.abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1) / np.sqrt(\n",
    "            (y2 - y1) ** 2 + (x2 - x1) ** 2)\n",
    "        distances.append(distance)\n",
    "    if index_min < index_max - 1:\n",
    "      T_index = distances.index(max(distances))\n",
    "    else:\n",
    "      T_index = -index_min\n",
    "    return T_index + index_min\n",
    "\n",
    "\n",
    "def extract_drawing(img):\n",
    "  dst = cv2.bilateralFilter(img, 10, sigmaColor=15, sigmaSpace=15)\n",
    "  #dst = img.copy()\n",
    "  #max_occ = np.bincount(dst[dst > 0]).argmax()\n",
    "  #dst[dst == 0] = max_occ\n",
    "  threshed = np.ones(dst.shape, np.uint8) * 255\n",
    "  if np.any(dst < 255):\n",
    "      hist, _ = np.histogram(dst[dst < 255].flatten(), range(257))\n",
    "      thresh_val = maxDeviationThresh(hist)\n",
    "      mask = dst < thresh_val\n",
    "      threshed[mask] = 0\n",
    "  return threshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 119332,
     "status": "ok",
     "timestamp": 1613220452855,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "Nj8w1vciviWS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "p_dst = [(382, 219),(852, 219), (852, 537), (382, 537)]\n",
    "def computeHomographyRhomb(image, points):\n",
    "    img = image.copy()\n",
    "    point_rhomb = points[2] + (1,)\n",
    "    mask = np.ones(5, dtype=int)\n",
    "    mask[2] = 0\n",
    "    right_points = np.array(points)[np.ma.make_mask(mask)]\n",
    "    hm, status = cv2.findHomography(np.array(right_points), np.array(p_dst))\n",
    "    new_point = np.dot(hm, point_rhomb)\n",
    "    new_point = tuple(np.round(new_point/new_point[2]).astype(int))\n",
    "    center = new_point[0:2]\n",
    "    return center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 121653,
     "status": "ok",
     "timestamp": 1613220455178,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "3FNhhHGKyvH7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    im_embeddings = embeddings[:, :int(embeddings.shape[1] / 2)]\n",
    "    #im_embeggings_np = im_embeddings.numpy()\n",
    "    anchor_emb = embeddings[:, int(embeddings.shape[1] / 2):]\n",
    "    anchor_emb = tf.expand_dims(anchor_emb[0], axis=0)\n",
    "    #anchor_emb_np = anchor_emb.numpy()\n",
    "    dot_product = tf.matmul(im_embeddings, tf.transpose(anchor_emb))\n",
    "    #dot_product_np = dot_product.numpy()\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm_a = tf.reduce_sum(tf.square(im_embeddings), axis=1, keepdims=True)\n",
    "    #square_norm_a_np = square_norm_a.numpy()\n",
    "    square_norm_b = tf.reduce_sum(tf.square(anchor_emb), axis=1, keepdims=True)\n",
    "    #square_norm_b_np = square_norm_b.numpy()\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.add(square_norm_a, square_norm_b - 2.0*dot_product)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), float)\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "    #distances_np = distances.numpy()\n",
    "    return distances\n",
    "\n",
    "def batch_hard_triplet_loss(y_true, y_pred):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    \n",
    "    #margin = 1.\n",
    "    labels = y_true\n",
    "    squared=False\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    #label_np = labels.numpy()\n",
    "    embeddings = y_pred\n",
    "\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "    #pairwise_dist_np = pairwise_dist.numpy()\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    #mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    #mask_anchor_positive = tf.cast(mask_anchor_positive, float)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "    #anchor_positive_dist_np=anchor_positive_dist.numpy()\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=0)\n",
    "\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    #mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    #mask_anchor_negative = tf.cast(mask_anchor_negative, float)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    #max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = tf.multiply(1-(tf.cast(labels, float)), pairwise_dist)\n",
    "    #anchor_negative_dist_np = anchor_negative_dist.numpy()\n",
    "    # shape (batch_size,)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_negative_dist, zero)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "    D = hardest_positive_dist - hardest_negative_dist\n",
    "    margin = tf.math.log(1 + tf.math.exp(D))\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    #triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):   \n",
    "    \n",
    "\n",
    "    labels = y_true\n",
    "    squared = False\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    margin = 1.\n",
    "    embeddings = y_pred\n",
    "\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_positive_dist, zero)\n",
    "    positive_non_zero = anchor_positive_dist[where]\n",
    "    # shape (batch_size, 1)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "\n",
    "    anchor_negative_dist = tf.multiply(1 - (tf.cast(labels, float)), pairwise_dist)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_negative_dist, zero)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "\n",
    "    positive_less_negative = tf.less_equal(positive_non_zero, hardest_negative_dist - margin)\n",
    "    positive_less_negative = tf.cast(positive_less_negative, float)\n",
    "    accuracy = tf.reduce_mean(positive_less_negative)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rocf2_env'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CONDA_DEFAULT_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as T\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../first_model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "root='../' #modificare se cartella rinominata\n",
    "\n",
    "model_folder=root + 'first_model'\n",
    "result_folder=root + 'results'\n",
    "template_dic={\n",
    "    0:'best_model_triplet_cross_transfer.hdf5',\n",
    "    1:'best_model_triplet_face_transfer.hdf5',\n",
    "    2:'best_model_triplet_rail_transfer.hdf5',\n",
    "    3:'best_model_triplet_rombo_transfer.hdf5',\n",
    "    4:'best_model_triplet_rett_diag_transfer.hdf5',\n",
    "    5:'best_model_triplet_rect_transfer.hdf5',\n",
    "    6:'best_model_triplet_cross_vert_transfer.hdf5'\n",
    "}\n",
    "\n",
    "model_folder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122213,
     "status": "ok",
     "timestamp": 1613220455742,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "tVg7LHRKvzGL",
    "outputId": "2bbf8518-c3ad-4655-a8c7-31049e2ca397"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    " \n",
    "class Grid():\n",
    "    def __init__(self, coords):\n",
    "        self.x = coords[0] \n",
    "        self.y = coords[1] \n",
    "        self.w = np.abs(coords[0] - coords[2])\n",
    "        self.h = np.abs(coords[1] - coords[3])\n",
    "        pad = 50\n",
    "        step = 10\n",
    "        row =  np.arange(self.x-pad, self.x+pad+1, step=step, dtype=int)\n",
    "        column = np.arange(self.y-pad, self.y+pad+1, step=step, dtype=int)\n",
    "        self.grid = np.transpose([np.tile(row, len(column)), np.repeat(column, len(row))])\n",
    "        pad_a = 10\n",
    "        self.actions = [\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h),\n",
    "            lambda x, y, w, h: (x, y, w, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h + pad_a),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    \n",
    "    def visualize(self, image, model, input_shape, template, idx, name):               \n",
    "        min_val = np.inf\n",
    "        best_embeddings = None\n",
    "        save_min = False\n",
    "\n",
    "        dataset_images = []\n",
    "\n",
    "        # start_time = datetime.now()\n",
    "        for i in range(len(self.grid)):                     \n",
    "            x, y = self.grid[i]\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            ROI = image[y:y + self.h, x:x + self.w]\n",
    "            if ROI.size == 0:\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                plt.show()     \n",
    "\n",
    "            # threshed =  np.array(extract_drawing(ROI))\n",
    "            input_img = background_thumbnail(ROI, 'L', (input_shape[0], input_shape[1]))\n",
    "            \n",
    "            input_img = input_img.astype('float32')\n",
    "            input_img /= 255\n",
    "            input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)            \n",
    "            #plt.imshow(input_img[:,:,0], cmap='gray')            \n",
    "            #plt.show()\n",
    "            #print(input_img.shape)\n",
    "            #print(template.shape)\n",
    "            #inp = np.array([[input_img], [template]])\n",
    "            #print(inp.shape)\n",
    "            \n",
    "            # result = model.predict([[input_img.reshape(1,100,100,3)], [template.reshape(1,100,100,3)]])\n",
    "\n",
    "            dataset_images.append(input_img)\n",
    "            \n",
    "                #min_bbox = bbox\n",
    "            #if i in values:\n",
    "              #print('done percent {} of template {}'.format(10*np.where(values == i)[0][0], idx))\n",
    "\n",
    "        dataset_anchors = [template for i in range(len(dataset_images))]\n",
    "        \n",
    "        dataset_images = np.array(dataset_images)\n",
    "        dataset_anchors = np.array(dataset_anchors)\n",
    "        result = model.predict([dataset_images, dataset_anchors], batch_size=32)\n",
    "\n",
    "        for i in range(len(result)):\n",
    "            distance = _pairwise_distances(np.array([result[i]]), squared=False).numpy()[0, 0]\n",
    "            if distance < min_val:\n",
    "                min_val = distance\n",
    "                best_embeddings = result[i]\n",
    "                save_min = True\n",
    "                x, y = self.grid[i]\n",
    "                min_x = max(0, x)\n",
    "                min_y = max(0, y)\n",
    "                \n",
    "                min_input = dataset_images    \n",
    "\n",
    "        done = False\n",
    "        min_w = self.w\n",
    "        min_h = self.h\n",
    "        min_x2 = min_x\n",
    "        min_y2 = min_y\n",
    "        iteraction = 0\n",
    "       \n",
    "        while not done and iteraction < 5:\n",
    "          found_min = False\n",
    "          dataset_images = []\n",
    "          coords_actions = []\n",
    "          for action in self.actions:\n",
    "            (x, y, w, h) = action(min_x, min_y, min_w, min_h)\n",
    "            coords_actions.append([x, y, w, h])\n",
    "            ROI = image[y:y + h, x:x + w]\n",
    "        #   threshed = np.array(extract_drawing(ROI))\n",
    "            input_img = background_thumbnail(ROI, 'L',\n",
    "                                        (input_shape[0], input_shape[1]))\n",
    "            input_img = input_img.astype('float32')\n",
    "            input_img /= 255\n",
    "            input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)\n",
    "            #plt.imshow(input_img[:,:,0], cmap='gray')\n",
    "            #plt.show()\n",
    "            dataset_images.append(input_img)\n",
    "\n",
    "            #   result = model.predict([[input_img.reshape(1,100,100,3)], [template.reshape(1,100,100,3)]])\n",
    "            #   embeddings = result\n",
    "            #   result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n",
    "            #   if result < min_val:\n",
    "            #       min_val = result\n",
    "            #       min_x2 = x\n",
    "            #       min_y2 = y\n",
    "            #       min_w = w\n",
    "            #       min_h = h\n",
    "            #       min_input = input_img\n",
    "            #       found_min = True\n",
    "          dataset_anchors = [template for i in range(len(dataset_images))]\n",
    "          dataset_images = np.array(dataset_images)\n",
    "          dataset_anchors = np.array(dataset_anchors)\n",
    "          result = model.predict([dataset_images, dataset_anchors], batch_size=32)\n",
    "\n",
    "          for i in range(len(result)):\n",
    "            distance = _pairwise_distances(np.array([result[i]]), squared=False).numpy()[0, 0]\n",
    "            if distance < min_val:\n",
    "                min_val = distance\n",
    "                best_embeddings = result[i]\n",
    "                # (x, y, w, h)\n",
    "                min_x2 = coords_actions[i][0]\n",
    "                min_y2 = coords_actions[i][1]\n",
    "                min_w = coords_actions[i][2]\n",
    "                min_h = coords_actions[i][3]\n",
    "                min_input = input_img\n",
    "                found_min = True\n",
    "          print('minval: {}'.format(min_val))\n",
    "\n",
    "          if found_min:\n",
    "            min_x = min_x2\n",
    "            min_y = min_y2\n",
    "            w = min_w\n",
    "            h = min_h\n",
    "          else:\n",
    "            done = True\n",
    "          iteraction += 1\n",
    "          print('done iteration {}'.format(iteraction))\n",
    "        \n",
    "        # end_time = datetime.now()\n",
    "        # print('Duration of executing the first round of predictions: {}'.format(end_time-start_time))\n",
    "        # print('minval: {}'.format(min_val))\n",
    "\n",
    "        #print(min_bbox)\n",
    "        clone2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.rectangle(clone2, (min_x2, min_y2), (min_x2 + min_w, min_y2 + min_h), color=(255, 0, 0))        \n",
    "        cv2.putText(clone2, str(min_val), (x + 20, y + 80), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "          color=(0, 0, 255))                \n",
    "        cv2.rectangle(clone2, (self.x, self.y), (self.x+self.w, self.y+self.h), color=(0,0,255))\n",
    "        #cv2.rectangle(clone2, (min_x+min_bbox[0], min_y+min_bbox[1]), (min_x+min_bbox[0]+min_bbox[2], min_y+min_bbox[1]+min_bbox[3]), color=(0,255,0))\n",
    "        #plt.imshow(cv2.cvtColor(clone2, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show() \n",
    "        #plt.close('all')           \n",
    "        cv2.imwrite(os.path.join(result_folder, name, 'minimum_'+str(idx)+'.png'), clone2)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        ax.ravel()[0].imshow(min_input[:,:,0], cmap='gray')\n",
    "        ax.ravel()[1].imshow(template[:,:,0], cmap='gray')\n",
    "        plt.savefig(os.path.join(result_folder, name, 'input_'+str(idx)+'.png'))\n",
    "        #plt.show()\n",
    "        plt.close('all')    \n",
    "        print('done template {}'.format(idx))    \n",
    "        return min_val, math.hypot(int(min_x2-min_w/2-(self.x-self.w/2)), int(min_y2-min_h/2-(self.y-self.h/2))), (min_x2, min_y2, min_w, min_h)\n",
    "      \n",
    "class Visualization():\n",
    "    def __init__(self, name, image, points, templates, shape, writer):\n",
    "        self.img = image\n",
    "        self.name = name\n",
    "        self.grids=[]\n",
    "        for point in points.values():\n",
    "            self.grids.append(Grid(point))\n",
    "        self.templates = templates\n",
    "        self.input_shape = shape\n",
    "        self.scores=[]\n",
    "        self.distances=[]\n",
    "        self.rects=[]\n",
    "        self.writer = writer\n",
    "  \n",
    "    def run(self):\n",
    "        if not os.path.isdir(os.path.join(result_folder, self.name)):\n",
    "            os.makedirs(os.path.join(result_folder, self.name))\n",
    "        for i in range(len(self.templates)):\n",
    "                   \n",
    "            #template = np.reshape(self.templates[i], self.input_shape)\n",
    "            template = self.templates[i]\n",
    "            template =  np.repeat(template[..., np.newaxis], 3, -1)\n",
    "            self.model = load_model(os.path.join(model_folder, template_dic[i]), custom_objects={'batch_hard_triplet_loss': batch_hard_triplet_loss,\n",
    "                                                                                         'compute_accuracy_hard': compute_accuracy})               \n",
    "            #plot_model(self.model, show_shapes=True)\n",
    "            max_val, distance, rect = self.grids[i].visualize(self.img, self.model, self.input_shape, template, i, self.name)\n",
    "            self.scores.append(max_val)\n",
    "            self.distances.append(distance)\n",
    "            self.rects.append(rect)\n",
    "            T.clear_session()\n",
    "            del self.model          \n",
    "            \n",
    "        self.writer.writerow({'names':self.name, 'scores': self.scores, 'distances':self.distances, 'rect':self.rects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8983911,
     "status": "ok",
     "timestamp": 1613232068385,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "419xM1dlWT8d",
    "outputId": "8919d213-0788-44f9-9af2-7194ce2dec6d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RC001' 'RC002' 'RC003' 'RC004' 'RC009' 'RC011' 'RC012' 'RC013' 'RC014'\n",
      " 'RC015' 'RC016' 'RC018' 'RC021' 'RC023' 'RC024' 'RC025' 'RC026' 'RC028'\n",
      " 'RC029' 'RC030' 'RC031' 'RC034' 'RC036' 'RC037' 'RC038' 'RC039' 'RC041'\n",
      " 'RC042' 'RC043' 'RC045' 'RC046' 'RC047' 'RC048' 'RC049' 'RC050' 'RC051'\n",
      " 'RC052' 'RC054' 'RC055' 'RC056' 'RC057' 'RC059' 'RC060' 'RC061' 'RC062'\n",
      " 'RC063' 'RC065' 'RC066' 'RC069' 'RC070' 'RC071' 'RC073' 'RC074' 'RC075'\n",
      " 'RC076' 'RC077' 'RC078' 'RC079' 'RC082' 'RC083' 'RC084' 'RC085' 'RC086'\n",
      " 'RC087' 'RC088' 'RC089' 'RC090' 'RC091' 'RC092' 'RC093' 'RC094' 'RC095'\n",
      " 'RC096' 'RC097' 'RC099' 'RC100' 'RC101' 'RC102' 'RC103' 'RC104' 'RC105'\n",
      " 'RC106' 'RC107' 'RC108' 'RC109' 'RC110' 'RC111' 'RC112' 'RC114' 'RC115'\n",
      " 'RC116' 'RC117' 'RC120' 'RC121' 'RC122' 'RC123' 'RC124' 'RC125' 'RC126'\n",
      " 'RC127' 'RC128' 'RC129' 'RC130' 'RC131' 'RC134' 'RC135' 'RC136' 'RC137'\n",
      " 'RC138' 'RC139' 'RC141' 'RC143' 'RC144' 'RC145' 'RC147' 'RC149' 'RC150'\n",
      " 'RC151' 'RC152' 'RC153' 'RC154' 'RC155' 'RC156' 'RC157' 'RC158' 'RC159'\n",
      " 'RC160' 'RC161' 'RC162' 'RC163' 'RC164' 'RC165' 'RC168' 'RC169' 'RC170'\n",
      " 'RC171' 'RC172' 'RC173' 'RC174' 'RC175' 'RC176' 'RC177' 'RC178' 'RC179'\n",
      " 'RC181' 'RC182' 'RC185' 'RC186' 'RC187' 'RC188' 'RC189' 'RC190' 'RC191'\n",
      " 'RC193' 'RC195' 'RC196' 'RC197' 'RC199' 'RC200' 'RC201' 'RC202' 'RC204'\n",
      " 'RC205' 'RC206' 'RC207' 'RC209' 'RC211' 'RC212' 'RC213' 'RC214' 'RC215'\n",
      " 'RC216' 'RC217' 'RC218' 'RC219' 'RC220' 'RC222' 'RC224' 'RC225' 'RC226'\n",
      " 'RC228' 'RC229' 'RC230' 'RC231' 'RC232' 'RC236' 'RC237' 'RC238' 'RC239'\n",
      " 'RC240' 'RC241' 'RC243' 'RC245' 'RC246' 'RC247' 'RC248' 'RC249' 'RC250'\n",
      " 'RC252' 'RC254' 'RC255' 'RC256' 'RC257' 'RC258' 'RC259' 'RC261' 'RC263'\n",
      " 'RC264' 'RC265' 'RC267' 'RC268' 'RC269' 'RC270' 'RC271' 'RC272' 'RC273'\n",
      " 'RC274' 'RC276' 'RC277' 'RC278' 'RC279' 'RC280' 'RC281' 'RC282' 'RC283'\n",
      " 'RC284' 'RC285' 'RC286' 'RC287' 'RC288' 'RC289' 'RC290' 'RC291' 'RC292'\n",
      " 'RC294' 'RC295' 'RC296' 'RC297' 'RC298' 'RC299' 'RC300' 'RC322' 'RC324'\n",
      " 'RC325' 'RC326' 'RC327' 'RC328' 'RC329' 'RC330' 'RC331' 'RC332' 'RC333'\n",
      " 'RC335' 'RC336' 'RC337' 'RC338' 'RC339' 'RC340' 'RC341' 'RC342' 'RC343'\n",
      " 'RC344' 'RC345' 'RC346' 'RC347' 'RC348' 'RC349' 'RC351' 'RC352' 'RC353'\n",
      " 'RC354' 'RC356' 'RC357' 'RC358' 'RC359' 'RC360' 'RC361' 'RC362' 'RC363'\n",
      " 'RC364' 'RC365' 'RC366' 'RC367' 'RC368' 'RC369' 'RC370' 'RC372' 'RC373'\n",
      " 'RC374' 'RC375' 'RC376' 'RC377' 'RC378' 'RC379' 'RC380' 'RC381' 'RC382'\n",
      " 'RC385' 'RC386' 'RC387' 'RC388' 'RC389' 'RC390' 'RC392' 'RC393' 'RC394'\n",
      " 'RC395' 'RC397' 'RC398' 'RC399' 'RC400' 'RC401' 'RC402' 'RC403' 'RC404'\n",
      " 'RC405' 'RC406' 'RC407' 'RC408' 'RC409' 'RC411' 'RC412' 'RC413' 'RC414'\n",
      " 'RC415' 'RC416' 'RC417' 'RC418' 'RC419' 'RC420' 'RC421' 'RC422' 'RC424'\n",
      " 'RC425' 'RC426' 'RC427' 'RC428' 'RC429' 'RC430' 'RC431' 'RC432' 'RC433'\n",
      " 'RC458' 'RC299' 'RC299' 'RC299']\n",
      "image2 of 105\n",
      "RC299.png\n",
      "minval: 68.82611846923828\n",
      "done iteration 1\n",
      "done template 0\n",
      "minval: 26.289417266845703\n",
      "done iteration 1\n",
      "minval: 26.289417266845703\n",
      "done iteration 2\n",
      "done template 1\n",
      "minval: 30.361528396606445\n",
      "done iteration 1\n",
      "done template 2\n",
      "minval: 24.106897354125977\n",
      "done iteration 1\n",
      "done template 3\n",
      "minval: 38.692420959472656\n",
      "done iteration 1\n",
      "minval: 38.58024978637695\n",
      "done iteration 2\n",
      "minval: 38.58024978637695\n",
      "done iteration 3\n",
      "done template 4\n",
      "minval: 28.71186065673828\n",
      "done iteration 1\n",
      "done template 5\n",
      "minval: 21.22948455810547\n",
      "done iteration 1\n",
      "done template 6\n",
      "349076\n",
      "loop time: 3.906902885437012m\n",
      "total_time: 3.906902885437012m\n",
      "image3 of 105\n",
      "RC300.png\n",
      "minval: 20.841794967651367\n",
      "done iteration 1\n",
      "done template 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17824/3762756726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVisualization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhomography\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mor_points2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m#app = Visualization('APR2018_GR270418130633-064', homography, or_points, templates, input_shape, writer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mcsv_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17824/1952809737.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             self.model = load_model(os.path.join(model_folder, template_dic[i]), custom_objects={'batch_hard_triplet_loss': batch_hard_triplet_loss,\n\u001b[1;32m--> 193\u001b[1;33m                                                                                          'compute_accuracy_hard': compute_accuracy})               \n\u001b[0m\u001b[0;32m    194\u001b[0m             \u001b[1;31m#plot_model(self.model, show_shapes=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mmax_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    182\u001b[0m     if (h5py is not None and (\n\u001b[0;32m    183\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 184\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m--> 178\u001b[1;33m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    107\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    371\u001b[0m             custom_objects=dict(\n\u001b[0;32m    372\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    374\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    985\u001b[0m     \"\"\"\n\u001b[0;32m    986\u001b[0m     input_tensors, output_tensors, created_layers = reconstruct_from_config(\n\u001b[1;32m--> 987\u001b[1;33m         config, custom_objects)\n\u001b[0m\u001b[0;32m    988\u001b[0m     model = cls(inputs=input_tensors, outputs=output_tensors,\n\u001b[0;32m    989\u001b[0m                 name=config.get('name'))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   2027\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2028\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2029\u001b[1;33m           \u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2031\u001b[0m   \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mprocess_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnest_if_single_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1977\u001b[1;33m       \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1979\u001b[0m       \u001b[1;31m# Update node index map.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    717\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[1;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     output, mean, variance = tf_utils.smart_cond(training, train_op,\n\u001b[1;32m--> 604\u001b[1;33m                                                  _fused_batch_norm_inference)\n\u001b[0m\u001b[0;32m    605\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     63\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m     64\u001b[0m   return smart_module.smart_cond(\n\u001b[1;32m---> 65\u001b[1;33m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[1;32m---> 59\u001b[1;33m                                  name=name)\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1175\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[0;32m   1176\u001b[0m       not context.executing_eagerly()):\n\u001b[1;32m-> 1177\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcond_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m   \u001b[1;31m# We needed to make true_fn/false_fn keyword arguments for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36mcond_v2\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mtrue_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         func_graph=util.CondBranchFuncGraph(\n\u001b[1;32m---> 82\u001b[1;33m             true_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         op_return_value=pred)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, collections, capture_by_value)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mouter\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfailing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFuncGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2809\u001b[0m     \u001b[1;31m# TODO(skyewm): fold as much of the above as possible into the C\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2810\u001b[0m     \u001b[1;31m# implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2811\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scoped_c_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2812\u001b[0m     \u001b[1;31m# The C API requires all ops to have shape functions. Disable this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2813\u001b[0m     \u001b[1;31m# requirement (many custom ops do not have shape functions, and we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Note: when we're destructing the global context (i.e when the process is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# terminating) we may have already deleted other modules. By capturing the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    " \n",
    "# root='./gdrive/My Drive/thesis' #modificare se cartella rinominata\n",
    "\n",
    "label_dict={\n",
    "    'cross.png':0,\n",
    "    'face.png':1,\n",
    "    'rail.png':2,\n",
    "    'rombo.png':3,\n",
    "    'rett_diag.png':4,\n",
    "    'rect.png':5,\n",
    "    'cross_vert.png':6\n",
    "}\n",
    "or_points = {\n",
    "    \"cross\":[324,119,378,373],\n",
    "    \"face\":[742, 287, 829, 373],\n",
    "    \"rail\":[617, 383, 847, 534],\n",
    "    \"rhomb\":[852, 229, 531],\n",
    "    \"rett_diag\":[379, 300, 502, 456],\n",
    "    \"rect\":[360, 525, 510, 680],\n",
    "    \"cross_vert\":[502, 540, 810, 661]\n",
    "}\n",
    "scale_percent = 100\n",
    "pad = 0\n",
    " \n",
    "def unique_color(img):\n",
    "    mask = img>0\n",
    "    only_color = img[mask]\n",
    "    colors, count = np.unique(only_color, return_counts=True)\n",
    "    max_color = colors[count.argmax()]\n",
    "    img[np.logical_not(mask)] = max_color\n",
    "    return img\n",
    " \n",
    "input_shape = (100,100,1)\n",
    "template_folder=os.path.join(root, 'templates')\n",
    "templates = np.zeros((7,input_shape[0], input_shape[1]))\n",
    "for img in os.listdir(template_folder):\n",
    "    if img != 'template.png':\n",
    "        template = background_thumbnail(cv2.imread(os.path.join(template_folder, img),\n",
    "                                                          cv2.IMREAD_GRAYSCALE), 'L', (input_shape[0], input_shape[1]))        \n",
    "        template = template.astype('float32')\n",
    "        template /= 255\n",
    "        templates[label_dict[img]] = template\n",
    "hom_folder = os.path.join(root, 'new_sample')\n",
    "file_j = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).set_index('name')\n",
    "img_list = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).loc[:, 'name'].values\n",
    "\n",
    " \n",
    "if not os.path.isdir(os.path.join(root, 'results')):\n",
    "    os.makedirs(os.path.join(root, 'results'))\n",
    "fieldnames = ['names', 'scores', 'distances', 'rect']\n",
    "if not os.path.isfile(os.path.join(root, 'results', 'scores.csv')):\n",
    "  with open(os.path.join(root, 'results', 'scores.csv'), \"w\") as f:\n",
    "            f.write(','.join(fieldnames)+'\\n')\n",
    " \n",
    "folders = pd.read_csv(os.path.join(root, 'results', 'scores.csv'), header=0, usecols=['names']).values.squeeze()\n",
    "print(folders)\n",
    "count = 1\n",
    "total_time = 0\n",
    "for image in os.listdir(hom_folder):\n",
    "  if image.endswith('.png'):\n",
    "    print(\"image{} of {}\".format(count, len(os.listdir(hom_folder))))\n",
    "    #homography = cv2.imread(os.path.join(hom_folder, 'APR2018_GR270418130633-064.png'))   \n",
    "    #if image[:-4] not in folders:\n",
    "    start_time = time.time()\n",
    "    print(image)\n",
    "    homography = cv2.imread(os.path.join(hom_folder, image), cv2.IMREAD_GRAYSCALE)\n",
    "    #homography = unique_color(homography)\n",
    "    or_points2 = copy.deepcopy(or_points)      \n",
    "    points = np.array(file_j.loc[image[:-4]].to_numpy()[0])\n",
    "    if points.shape ==(1,):\n",
    "      points = np.array(points[0])\n",
    "    points = [tuple(x) for x in points]\n",
    "    r_points = computeHomographyRhomb(homography, points)\n",
    "    or_points2['rhomb'].insert(2, r_points[0])\n",
    "    homography = cv2.medianBlur(homography, 3)\n",
    "    width = int(homography.shape[1] * scale_percent / 100)\n",
    "    height = int(homography.shape[0] * scale_percent / 100)\n",
    "    homography = cv2.resize(homography, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    for x,y in or_points2.items():\n",
    "        or_points2[x] = np.array([int(p*(scale_percent/100)) for p in y])\n",
    "        or_points2[x][0:2]-=pad\n",
    "        or_points2[x][2:]+=pad\n",
    "        or_points2[x] = or_points2[x].tolist()\n",
    "  \n",
    "    csv_file = open(os.path.join(root, 'results', 'scores.csv'), mode='a')\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    app = Visualization(image[:-4], homography, or_points2, templates, input_shape, writer)\n",
    "    #app = Visualization('APR2018_GR270418130633-064', homography, or_points, templates, input_shape, writer)\n",
    "    app.run()      \n",
    "    csv_file.close()\n",
    "    del app\n",
    "    print(gc.collect())\n",
    "    end_time = time.time()\n",
    "    loop_time = (end_time - start_time) / 60\n",
    "    total_time += loop_time\n",
    "    print('loop time: {}m'.format(loop_time))\n",
    "    print('total_time: {}m'.format(total_time))\n",
    "  count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1390454821365390554\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2931996279404884088\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3178115892\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3135183590251079993\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1624139991520789141\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUMmlDPg/I4jxSt7s+biqV",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "test_on_homog.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5d073f89a8355d11ddac5a448b200c1c879fa5680801c761ed6fcc477c84e1a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('rocf2_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
