{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wojXqpbzAMdD"
   },
   "source": [
    "In questo notebook le reti neurali vengono utilizzate per trovare e analizzare i pattern piÃ¹ complessi. Basta eseguire Runtime->esegui tutte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1613220334480,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "oQNamwhVsrbd",
    "outputId": "886112dd-e4e1-4cf8-935a-59af0e4ba002"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sng4-l9sAfUf"
   },
   "source": [
    "IMPORTANTE: queste versioni non vanno cambiate. Versioni successive di Tensorflow non fanno girare il codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118414,
     "status": "ok",
     "timestamp": 1613220451924,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "otMuOedo8nnQ",
    "outputId": "cb678c37-e5ca-4df5-c427-909f0e4960e5",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: q in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (2.6)\n",
      "Requirement already satisfied: keras==2.3.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (5.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from keras==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: q in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (2.6)\n",
      "Requirement already satisfied: tensorflow==2.2.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (3.14.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.36.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (0.12.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.19.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.30.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\aida\\anaconda3\\envs\\rocf2_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install q keras==2.3.1\n",
    "!pip install q tensorflow==2.2.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 118415,
     "status": "ok",
     "timestamp": 1613220451929,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "HJHVz2mYvGla",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def background_thumbnail(template, modality, thumbnail_size=(200,200)):\n",
    "    foreground = Image.fromarray(template).convert(modality)\n",
    "    background = Image.new(modality, thumbnail_size, \"white\")\n",
    "    foreground.thumbnail(thumbnail_size)\n",
    "    (w, h) = foreground.size\n",
    "    upper_left=(int((thumbnail_size[0] - w) / 2), int((thumbnail_size[1] - h) / 2))\n",
    "    background.paste(foreground, upper_left)\n",
    "    return np.array(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 119333,
     "status": "ok",
     "timestamp": 1613220452852,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "kir95NDuvfuY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def maxDeviationThresh(hist):\n",
    "    maximum = max(hist)\n",
    "    index_max = list(hist).index(maximum)\n",
    "    index_min = 0\n",
    "    for i in range(0, index_max):\n",
    "        if not hist[i] and hist[i+1]:\n",
    "            index_min = i\n",
    "            break\n",
    "    \n",
    "    distances = []\n",
    "    x1 = index_min\n",
    "    y1 = hist[index_min]\n",
    "    x2 = index_max\n",
    "    y2 = hist[index_max]\n",
    "    for i in range(index_min + 1, index_max):\n",
    "        x0 = i\n",
    "        y0 = hist[i]\n",
    "        distance = np.abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1) / np.sqrt(\n",
    "            (y2 - y1) ** 2 + (x2 - x1) ** 2)\n",
    "        distances.append(distance)\n",
    "    if index_min < index_max - 1:\n",
    "      T_index = distances.index(max(distances))\n",
    "    else:\n",
    "      T_index = -index_min\n",
    "    return T_index + index_min\n",
    "\n",
    "\n",
    "def extract_drawing(img):\n",
    "  dst = cv2.bilateralFilter(img, 10, sigmaColor=15, sigmaSpace=15)\n",
    "  #dst = img.copy()\n",
    "  #max_occ = np.bincount(dst[dst > 0]).argmax()\n",
    "  #dst[dst == 0] = max_occ\n",
    "  threshed = np.ones(dst.shape, np.uint8) * 255\n",
    "  if np.any(dst < 255):\n",
    "      hist, _ = np.histogram(dst[dst < 255].flatten(), range(257))\n",
    "      thresh_val = maxDeviationThresh(hist)\n",
    "      mask = dst < thresh_val\n",
    "      threshed[mask] = 0\n",
    "  return threshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 119332,
     "status": "ok",
     "timestamp": 1613220452855,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "Nj8w1vciviWS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "p_dst = [(382, 219),(852, 219), (852, 537), (382, 537)]\n",
    "def computeHomographyRhomb(image, points):\n",
    "    img = image.copy()\n",
    "    point_rhomb = points[2] + (1,)\n",
    "    mask = np.ones(5, dtype=int)\n",
    "    mask[2] = 0\n",
    "    right_points = np.array(points)[np.ma.make_mask(mask)]\n",
    "    hm, status = cv2.findHomography(np.array(right_points), np.array(p_dst))\n",
    "    new_point = np.dot(hm, point_rhomb)\n",
    "    new_point = tuple(np.round(new_point/new_point[2]).astype(int))\n",
    "    center = new_point[0:2]\n",
    "    return center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 121653,
     "status": "ok",
     "timestamp": 1613220455178,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "3FNhhHGKyvH7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    im_embeddings = embeddings[:, :int(embeddings.shape[1] / 2)]\n",
    "    #im_embeggings_np = im_embeddings.numpy()\n",
    "    anchor_emb = embeddings[:, int(embeddings.shape[1] / 2):]\n",
    "    anchor_emb = tf.expand_dims(anchor_emb[0], axis=0)\n",
    "    #anchor_emb_np = anchor_emb.numpy()\n",
    "    dot_product = tf.matmul(im_embeddings, tf.transpose(anchor_emb))\n",
    "    #dot_product_np = dot_product.numpy()\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm_a = tf.reduce_sum(tf.square(im_embeddings), axis=1, keepdims=True)\n",
    "    #square_norm_a_np = square_norm_a.numpy()\n",
    "    square_norm_b = tf.reduce_sum(tf.square(anchor_emb), axis=1, keepdims=True)\n",
    "    #square_norm_b_np = square_norm_b.numpy()\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.add(square_norm_a, square_norm_b - 2.0*dot_product)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.cast(tf.equal(distances, 0.0), float)\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "    #distances_np = distances.numpy()\n",
    "    return distances\n",
    "\n",
    "def batch_hard_triplet_loss(y_true, y_pred):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    \n",
    "    #margin = 1.\n",
    "    labels = y_true\n",
    "    squared=False\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    #label_np = labels.numpy()\n",
    "    embeddings = y_pred\n",
    "\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "    #pairwise_dist_np = pairwise_dist.numpy()\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    #mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    #mask_anchor_positive = tf.cast(mask_anchor_positive, float)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "    #anchor_positive_dist_np=anchor_positive_dist.numpy()\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=0)\n",
    "\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    #mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    #mask_anchor_negative = tf.cast(mask_anchor_negative, float)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    #max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = tf.multiply(1-(tf.cast(labels, float)), pairwise_dist)\n",
    "    #anchor_negative_dist_np = anchor_negative_dist.numpy()\n",
    "    # shape (batch_size,)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_negative_dist, zero)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "    D = hardest_positive_dist - hardest_negative_dist\n",
    "    margin = tf.math.log(1 + tf.math.exp(D))\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    #triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):   \n",
    "    \n",
    "\n",
    "    labels = y_true\n",
    "    squared = False\n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "    margin = 1.\n",
    "    embeddings = y_pred\n",
    "\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_positive_dist, zero)\n",
    "    positive_non_zero = anchor_positive_dist[where]\n",
    "    # shape (batch_size, 1)\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "\n",
    "    anchor_negative_dist = tf.multiply(1 - (tf.cast(labels, float)), pairwise_dist)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(anchor_negative_dist, zero)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "\n",
    "    positive_less_negative = tf.less_equal(positive_non_zero, hardest_negative_dist - margin)\n",
    "    positive_less_negative = tf.cast(positive_less_negative, float)\n",
    "    accuracy = tf.reduce_mean(positive_less_negative)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'rocf2_env'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CONDA_DEFAULT_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as T\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../first_model'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "\n",
    "\n",
    "root='../' #modificare se cartella rinominata\n",
    "\n",
    "model_folder=root + 'first_model'\n",
    "result_folder=root + 'results'\n",
    "template_dic={\n",
    "    0:'best_model_triplet_cross_transfer.hdf5',\n",
    "    1:'best_model_triplet_face_transfer.hdf5',\n",
    "    2:'best_model_triplet_rail_transfer.hdf5',\n",
    "    3:'best_model_triplet_rombo_transfer.hdf5',\n",
    "    4:'best_model_triplet_rett_diag_transfer.hdf5',\n",
    "    5:'best_model_triplet_rect_transfer.hdf5',\n",
    "    6:'best_model_triplet_cross_vert_transfer.hdf5'\n",
    "}\n",
    "\n",
    "model_folder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122213,
     "status": "ok",
     "timestamp": 1613220455742,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "tVg7LHRKvzGL",
    "outputId": "2bbf8518-c3ad-4655-a8c7-31049e2ca397"
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "class Grid():\n",
    "    def __init__(self, coords):\n",
    "        self.x = coords[0] \n",
    "        self.y = coords[1] \n",
    "        print(coords[0])\n",
    "        print(coords[2])\n",
    "        print(coords[0] - coords[2])\n",
    "        self.w = np.abs(coords[0] - coords[2])\n",
    "        self.h = np.abs(coords[1] - coords[3])\n",
    "        pad = 50\n",
    "        step = 10\n",
    "        row =  np.arange(self.x-pad, self.x+pad+1, step=step, dtype=int)\n",
    "        column = np.arange(self.y-pad, self.y+pad+1, step=step, dtype=int)\n",
    "        self.grid = np.transpose([np.tile(row, len(column)), np.repeat(column, len(row))])\n",
    "        pad_a = 10\n",
    "        self.actions = [\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h),\n",
    "            lambda x, y, w, h: (x, y, w, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h + pad_a),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    \n",
    "    def visualize(self, image, model, input_shape, template, idx, name):               \n",
    "        min_val = np.inf\n",
    "        save_min = False\n",
    "        for i in range(len(self.grid)):                     \n",
    "            x, y = self.grid[i]\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            ROI = image[y:y + self.h, x:x + self.w]\n",
    "            if ROI.size == 0:\n",
    "                plt.imshow(image, cmap='gray')\n",
    "                plt.show()  \n",
    "                print(\"y: \", y)         \n",
    "                print(\" self.h: \",  self.h)         \n",
    "                print(\"x: \", x)         \n",
    "                print(\"self.w: \", self.w)         \n",
    "                print(\"y + self.h: \", y + self.h)         \n",
    "                print(\"x + self.w: \", x + self.w)  \n",
    "                print(image[y:y + self.h, x:x + self.w])       \n",
    "\n",
    "            threshed =  np.array(extract_drawing(ROI))\n",
    "            input_img = background_thumbnail(threshed, 'L', (input_shape[0], input_shape[1]))\n",
    "            \n",
    "            input_img = input_img.astype('float32')\n",
    "            input_img /= 255\n",
    "            input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)            \n",
    "            #plt.imshow(input_img[:,:,0], cmap='gray')            \n",
    "            #plt.show()\n",
    "            #print(input_img.shape)\n",
    "            #print(template.shape)\n",
    "            #inp = np.array([[input_img], [template]])\n",
    "            #print(inp.shape)\n",
    "            \n",
    "            result = model.predict([[input_img.reshape(1,100,100,3)], [template.reshape(1,100,100,3)]])\n",
    "            embeddings = result\n",
    "            result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n",
    "            if result < min_val:\n",
    "                min_val = result\n",
    "                save_min = True\n",
    "                min_y = y\n",
    "                min_x = x\n",
    "                min_input = input_img\n",
    "                #min_bbox = bbox\n",
    "            #if i in values:\n",
    "              #print('done percent {} of template {}'.format(10*np.where(values == i)[0][0], idx))\n",
    "        \n",
    "        done = False\n",
    "        min_w = self.w\n",
    "        min_h = self.h\n",
    "        min_x2 = min_x\n",
    "        min_y2 = min_y\n",
    "        iteraction = 0\n",
    "        while not done and iteraction < 5:\n",
    "          found_min = False\n",
    "          for action in self.actions:\n",
    "              (x, y, w, h) = action(min_x, min_y, min_w, min_h)\n",
    "              ROI = image[y:y + h, x:x + w]\n",
    "              threshed = np.array(extract_drawing(ROI))\n",
    "              input_img = background_thumbnail(threshed, 'L',\n",
    "                                          (input_shape[0], input_shape[1]))\n",
    "              input_img = input_img.astype('float32')\n",
    "              input_img /= 255\n",
    "              input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)\n",
    "              #plt.imshow(input_img[:,:,0], cmap='gray')\n",
    "              #plt.show()\n",
    "              result = model.predict([[input_img.reshape(1,100,100,3)], [template.reshape(1,100,100,3)]])\n",
    "              embeddings = result\n",
    "              result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n",
    "              if result < min_val:\n",
    "                  min_val = result\n",
    "                  min_x2 = x\n",
    "                  min_y2 = y\n",
    "                  min_w = w\n",
    "                  min_h = h\n",
    "                  min_input = input_img\n",
    "                  found_min = True\n",
    "          if found_min:\n",
    "            min_x = min_x2\n",
    "            min_y = min_y2\n",
    "            w = min_w\n",
    "            h = min_h\n",
    "          else:\n",
    "            done = True\n",
    "          iteraction += 1\n",
    "          print('done iteration {}'.format(iteraction))\n",
    "        \n",
    "        #print(min_bbox)\n",
    "        clone2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.rectangle(clone2, (min_x2, min_y2), (min_x2 + min_w, min_y2 + min_h), color=(255, 0, 0))        \n",
    "        cv2.putText(clone2, str(min_val), (x + 20, y + 80), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "          color=(0, 0, 255))                \n",
    "        cv2.rectangle(clone2, (self.x, self.y), (self.x+self.w, self.y+self.h), color=(0,0,255))\n",
    "        #cv2.rectangle(clone2, (min_x+min_bbox[0], min_y+min_bbox[1]), (min_x+min_bbox[0]+min_bbox[2], min_y+min_bbox[1]+min_bbox[3]), color=(0,255,0))\n",
    "        #plt.imshow(cv2.cvtColor(clone2, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show() \n",
    "        #plt.close('all')           \n",
    "        cv2.imwrite(os.path.join(result_folder, name, 'minimum_'+str(idx)+'.png'), clone2)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        ax.ravel()[0].imshow(min_input[:,:,0], cmap='gray')\n",
    "        ax.ravel()[1].imshow(template[:,:,0], cmap='gray')\n",
    "        plt.savefig(os.path.join(result_folder, name, 'input_'+str(idx)+'.png'))\n",
    "        #plt.show()\n",
    "        plt.close('all')    \n",
    "        print('done template {}'.format(idx))    \n",
    "        return min_val, math.hypot(int(min_x2-min_w/2-(self.x-self.w/2)), int(min_y2-min_h/2-(self.y-self.h/2))), (min_x2, min_y2, min_w, min_h)\n",
    "      \n",
    "class Visualization():\n",
    "    def __init__(self, name, image, points, templates, shape, writer):\n",
    "        self.img = image\n",
    "        self.name = name\n",
    "        self.grids=[]\n",
    "        for point in points.values():\n",
    "            self.grids.append(Grid(point))\n",
    "        self.templates = templates\n",
    "        self.input_shape = shape\n",
    "        self.scores=[]\n",
    "        self.distances=[]\n",
    "        self.rects=[]\n",
    "        self.writer = writer\n",
    "  \n",
    " \n",
    "    def run(self):\n",
    "        if not os.path.isdir(os.path.join(result_folder, self.name)):\n",
    "            os.makedirs(os.path.join(result_folder, self.name))\n",
    "        for i in range(len(self.templates)):\n",
    "                   \n",
    "            #template = np.reshape(self.templates[i], self.input_shape)\n",
    "            template = self.templates[i]\n",
    "            template =  np.repeat(template[..., np.newaxis], 3, -1)\n",
    "            self.model = load_model(os.path.join(model_folder, template_dic[i]), custom_objects={'batch_hard_triplet_loss': batch_hard_triplet_loss,\n",
    "                                                                                         'compute_accuracy_hard': compute_accuracy})               \n",
    "            #plot_model(self.model, show_shapes=True)\n",
    "            max_val, distance, rect = self.grids[i].visualize(self.img, self.model, self.input_shape, template, i, self.name)\n",
    "            self.scores.append(max_val)\n",
    "            self.distances.append(distance)\n",
    "            self.rects.append(rect)\n",
    "            T.clear_session()\n",
    "            del self.model          \n",
    "            \n",
    "        self.writer.writerow({'names':self.name, 'scores': self.scores, 'distances':self.distances, 'rect':self.rects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8983911,
     "status": "ok",
     "timestamp": 1613232068385,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "419xM1dlWT8d",
    "outputId": "8919d213-0788-44f9-9af2-7194ce2dec6d",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n",
      "image2 of 11\n",
      "thesis-rey-ost_test_photos_301.png\n",
      "224\n",
      "(5, 2)\n",
      "[(825, 2580), (1780, 2565), (2055, 2965), (1725, 3280), (815, 3235)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "989\n",
      "-137\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 3\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 4\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "381355\n",
      "loop time: 5.2184973160425825m\n",
      "total_time: 5.2184973160425825m\n",
      "image3 of 11\n",
      "thesis-rey-ost_test_photos_302.png\n",
      "219\n",
      "(5, 2)\n",
      "[(830, 2330), (1785, 2290), (2230, 2490), (1590, 2905), (790, 2990)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1168\n",
      "-316\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done template 3\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 4\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "359827\n",
      "loop time: 4.843404150009155m\n",
      "total_time: 10.061901466051737m\n",
      "image4 of 11\n",
      "thesis-rey-ost_test_photos_303.png\n",
      "225\n",
      "(5, 2)\n",
      "[(605, 2330), (1505, 2500), (1915, 3100), (1450, 3190), (615, 3195)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1212\n",
      "-360\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "396428\n",
      "loop time: 4.85746742884318m\n",
      "total_time: 14.919368894894916m\n",
      "image5 of 11\n",
      "thesis-rey-ost_test_photos_304.png\n",
      "215\n",
      "(5, 2)\n",
      "[(760, 2295), (1615, 2240), (1920, 2430), (1580, 2755), (775, 2835)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1047\n",
      "-195\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done template 1\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 3\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "430894\n",
      "loop time: 4.89711784919103m\n",
      "total_time: 19.816486744085946m\n",
      "image6 of 11\n",
      "thesis-rey-ost_test_photos_305.png\n",
      "219\n",
      "(5, 2)\n",
      "[(760, 2485), (1835, 2480), (2170, 2800), (1780, 3035), (755, 3005)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1003\n",
      "-151\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 3\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 6\n",
      "437341\n",
      "loop time: 4.9429386258125305m\n",
      "total_time: 24.759425369898477m\n",
      "image7 of 11\n",
      "thesis-rey-ost_test_photos_306.png\n",
      "236\n",
      "(5, 2)\n",
      "[(875, 2375), (1645, 2405), (2155, 2685), (1685, 3030), (830, 3020)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1156\n",
      "-304\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 1\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 2\n",
      "done iteration 1\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "359827\n",
      "loop time: 4.897570085525513m\n",
      "total_time: 29.65699545542399m\n",
      "image8 of 11\n",
      "thesis-rey-ost_test_photos_307.png\n",
      "218\n",
      "(5, 2)\n",
      "[(850, 2325), (1775, 2280), (2120, 2565), (1795, 2855), (890, 2995)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1066\n",
      "-214\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done iteration 4\n",
      "done iteration 5\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 5\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 6\n",
      "437341\n",
      "loop time: 5.028984173138936m\n",
      "total_time: 34.685979628562926m\n",
      "image9 of 11\n",
      "thesis-rey-ost_test_photos_308.png\n",
      "230\n",
      "(5, 2)\n",
      "[(620, 2540), (1730, 2545), (2075, 2735), (1810, 3200), (615, 3115)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "966\n",
      "-114\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 6\n",
      "437353\n",
      "loop time: 4.881902281443278m\n",
      "total_time: 39.56788191000621m\n",
      "image10 of 11\n",
      "thesis-rey-ost_test_photos_310.png\n",
      "214\n",
      "(5, 2)\n",
      "[(1110, 2875), (1830, 2910), (2445, 3260), (1900, 3515), (1155, 3435)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1179\n",
      "-327\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 0\n",
      "done iteration 1\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "430899\n",
      "loop time: 4.94680825471878m\n",
      "total_time: 44.51469016472499m\n",
      "image11 of 11\n",
      "thesis-rey-ost_test_photos_311.png\n",
      "230\n",
      "(5, 2)\n",
      "[(845, 2430), (1630, 2390), (1955, 2615), (1650, 3050), (840, 3070)]\n",
      "324\n",
      "378\n",
      "-54\n",
      "742\n",
      "829\n",
      "-87\n",
      "617\n",
      "847\n",
      "-230\n",
      "852\n",
      "1032\n",
      "-180\n",
      "379\n",
      "502\n",
      "-123\n",
      "360\n",
      "510\n",
      "-150\n",
      "502\n",
      "810\n",
      "-308\n",
      "done iteration 1\n",
      "done template 0\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 1\n",
      "done iteration 1\n",
      "done template 2\n",
      "done iteration 1\n",
      "done iteration 2\n",
      "done iteration 3\n",
      "done template 3\n",
      "done iteration 1\n",
      "done template 4\n",
      "done iteration 1\n",
      "done template 5\n",
      "done iteration 1\n",
      "done template 6\n",
      "430899\n",
      "loop time: 5.090159006913503m\n",
      "total_time: 49.60484917163849m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    " \n",
    "# root='./gdrive/My Drive/thesis' #modificare se cartella rinominata\n",
    "\n",
    "label_dict={\n",
    "    'cross.png':0,\n",
    "    'face.png':1,\n",
    "    'rail.png':2,\n",
    "    'rombo.png':3,\n",
    "    'rett_diag.png':4,\n",
    "    'rect.png':5,\n",
    "    'cross_vert.png':6\n",
    "}\n",
    "or_points = {\n",
    "    \"cross\":[324,119,378,373],\n",
    "    \"face\":[742, 287, 829, 373],\n",
    "    \"rail\":[617, 383, 847, 534],\n",
    "    \"rhomb\":[852, 229, 531],\n",
    "    \"rett_diag\":[379, 300, 502, 456],\n",
    "    \"rect\":[360, 525, 510, 680],\n",
    "    \"cross_vert\":[502, 540, 810, 661]\n",
    "}\n",
    "scale_percent = 100\n",
    "pad = 0\n",
    " \n",
    "def unique_color(img):\n",
    "    mask = img>0\n",
    "    only_color = img[mask]\n",
    "    colors, count = np.unique(only_color, return_counts=True)\n",
    "    max_color = colors[count.argmax()]\n",
    "    print(max_color)\n",
    "    img[np.logical_not(mask)] = max_color\n",
    "    return img\n",
    " \n",
    "input_shape = (100,100,1)\n",
    "template_folder=os.path.join(root, 'templates')\n",
    "templates = np.zeros((7,input_shape[0], input_shape[1]))\n",
    "for img in os.listdir(template_folder):\n",
    "    if img != 'template.png':\n",
    "        template = background_thumbnail(cv2.imread(os.path.join(template_folder, img),\n",
    "                                                          cv2.IMREAD_GRAYSCALE), 'L', (input_shape[0], input_shape[1]))        \n",
    "        template = template.astype('float32')\n",
    "        template /= 255\n",
    "        templates[label_dict[img]] = template\n",
    "hom_folder = os.path.join(root, 'new_sample')\n",
    "file_j = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).set_index('name')\n",
    "img_list = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).loc[:, 'name'].values\n",
    "\n",
    " \n",
    "if not os.path.isdir(os.path.join(root, 'results')):\n",
    "    os.makedirs(os.path.join(root, 'results'))\n",
    "fieldnames = ['names', 'scores', 'distances', 'rect']\n",
    "if not os.path.isfile(os.path.join(root, 'results', 'scores.csv')):\n",
    "  with open(os.path.join(root, 'results', 'scores.csv'), \"w\") as f:\n",
    "            f.write(','.join(fieldnames)+'\\n')\n",
    " \n",
    "folders = pd.read_csv(os.path.join(root, 'results', 'scores.csv'), header=0, usecols=['names']).values.squeeze()\n",
    "print(folders)\n",
    "count = 1\n",
    "total_time = 0\n",
    "for image in os.listdir(hom_folder):\n",
    "  if image.endswith('.png'):\n",
    "    print(\"image{} of {}\".format(count, len(os.listdir(hom_folder))))\n",
    "    #homography = cv2.imread(os.path.join(hom_folder, 'APR2018_GR270418130633-064.png'))   \n",
    "    #if image[:-4] not in folders:\n",
    "    start_time = time.time()\n",
    "    print(image)\n",
    "    homography = unique_color(cv2.imread(os.path.join(hom_folder, image), cv2.IMREAD_GRAYSCALE))\n",
    "    #homography = unique_color(homography)\n",
    "    or_points2 = copy.deepcopy(or_points)      \n",
    "    points = np.array(file_j.loc[image[:-4]].to_numpy()[0])\n",
    "    if points.shape ==(1,):\n",
    "      points = np.array(points[0])\n",
    "    print(points.shape)\n",
    "    points = [tuple(x) for x in points]\n",
    "    print(points)\n",
    "    r_points = computeHomographyRhomb(homography, points)\n",
    "    or_points2['rhomb'].insert(2, r_points[0])\n",
    "    homography = cv2.medianBlur(homography, 3)\n",
    "    width = int(homography.shape[1] * scale_percent / 100)\n",
    "    height = int(homography.shape[0] * scale_percent / 100)\n",
    "    homography = cv2.resize(homography, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    for x,y in or_points2.items():\n",
    "        or_points2[x] = np.array([int(p*(scale_percent/100)) for p in y])\n",
    "        or_points2[x][0:2]-=pad\n",
    "        or_points2[x][2:]+=pad\n",
    "        or_points2[x] = or_points2[x].tolist()\n",
    "  \n",
    "    csv_file = open(os.path.join(root, 'results', 'scores.csv'), mode='a')\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    app = Visualization(image[:-4], homography, or_points2, templates, input_shape, writer)\n",
    "    #app = Visualization('APR2018_GR270418130633-064', homography, or_points, templates, input_shape, writer)\n",
    "    app.run()      \n",
    "    csv_file.close()\n",
    "    del app\n",
    "    print(gc.collect())\n",
    "    end_time = time.time()\n",
    "    loop_time = (end_time - start_time) / 60\n",
    "    total_time += loop_time\n",
    "    print('loop time: {}m'.format(loop_time))\n",
    "    print('total_time: {}m'.format(total_time))\n",
    "  count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUMmlDPg/I4jxSt7s+biqV",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "test_on_homog.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5d073f89a8355d11ddac5a448b200c1c879fa5680801c761ed6fcc477c84e1a9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('rocf2_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}