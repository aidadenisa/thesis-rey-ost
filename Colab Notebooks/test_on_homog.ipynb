{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_on_homog.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOUMmlDPg/I4jxSt7s+biqV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wojXqpbzAMdD"},"source":["In questo notebook le reti neurali vengono utilizzate per trovare e analizzare i pattern più complessi. Basta eseguire Runtime->esegui tutte"]},{"cell_type":"code","metadata":{"id":"oQNamwhVsrbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613220334480,"user_tz":-60,"elapsed":980,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}},"outputId":"886112dd-e4e1-4cf8-935a-59af0e4ba002"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sng4-l9sAfUf"},"source":["IMPORTANTE: queste versioni non vanno cambiate. Versioni successive di Tensorflow non fanno girare il codice."]},{"cell_type":"code","metadata":{"id":"otMuOedo8nnQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613220451924,"user_tz":-60,"elapsed":118414,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}},"outputId":"cb678c37-e5ca-4df5-c427-909f0e4960e5"},"source":["!pip install q keras==2.3.1\n","!pip install q tensorflow==2.2.0  "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n","Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.6/dist-packages (2.3.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n","Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 19kB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.32.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.36.2)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 42.3MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.19.5)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 30.8MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (53.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorflow 2.4.1\n","    Uninstalling tensorflow-2.4.1:\n","      Successfully uninstalled tensorflow-2.4.1\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HJHVz2mYvGla","executionInfo":{"status":"ok","timestamp":1613220451929,"user_tz":-60,"elapsed":118415,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}}},"source":["from PIL import Image\n","import numpy as np\n","\n","def background_thumbnail(template, modality, thumbnail_size=(200,200)):\n","    foreground = Image.fromarray(template).convert(modality)\n","    background = Image.new(modality, thumbnail_size, \"white\")\n","    foreground.thumbnail(thumbnail_size)\n","    (w, h) = foreground.size\n","    upper_left=(int((thumbnail_size[0] - w) / 2), int((thumbnail_size[1] - h) / 2))\n","    background.paste(foreground, upper_left)\n","    return np.array(background)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"kir95NDuvfuY","executionInfo":{"status":"ok","timestamp":1613220452852,"user_tz":-60,"elapsed":119333,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}}},"source":["import numpy as np\n","import cv2\n","from matplotlib import pyplot as plt\n","\n","\n","def maxDeviationThresh(hist):\n","    maximum = max(hist)\n","    index_max = list(hist).index(maximum)\n","    index_min = 0\n","    for i in range(0, index_max):\n","        if not hist[i] and hist[i+1]:\n","            index_min = i\n","            break\n","    \n","    distances = []\n","    x1 = index_min\n","    y1 = hist[index_min]\n","    x2 = index_max\n","    y2 = hist[index_max]\n","    for i in range(index_min + 1, index_max):\n","        x0 = i\n","        y0 = hist[i]\n","        distance = np.abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1) / np.sqrt(\n","            (y2 - y1) ** 2 + (x2 - x1) ** 2)\n","        distances.append(distance)\n","    if index_min < index_max - 1:\n","      T_index = distances.index(max(distances))\n","    else:\n","      T_index = -index_min\n","    return T_index + index_min\n","\n","\n","def extract_drawing(img):\n","  dst = cv2.bilateralFilter(img, 10, sigmaColor=15, sigmaSpace=15)\n","  #dst = img.copy()\n","  #max_occ = np.bincount(dst[dst > 0]).argmax()\n","  #dst[dst == 0] = max_occ\n","  threshed = np.ones(dst.shape, np.uint8) * 255\n","  if np.any(dst < 255):\n","      hist, _ = np.histogram(dst[dst < 255].flatten(), range(257))\n","      thresh_val = maxDeviationThresh(hist)\n","      mask = dst < thresh_val\n","      threshed[mask] = 0\n","  return threshed"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj8w1vciviWS","executionInfo":{"status":"ok","timestamp":1613220452855,"user_tz":-60,"elapsed":119332,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}}},"source":["import cv2\n","p_dst = [(382, 219),(852, 219), (852, 537), (382, 537)]\n","def computeHomographyRhomb(image, points):\n","    img = image.copy()\n","    point_rhomb = points[2] + (1,)\n","    mask = np.ones(5, dtype=int)\n","    mask[2] = 0\n","    right_points = np.array(points)[np.ma.make_mask(mask)]\n","    hm, status = cv2.findHomography(np.array(right_points), np.array(p_dst))\n","    new_point = np.dot(hm, point_rhomb)\n","    new_point = tuple(np.round(new_point/new_point[2]).astype(int))\n","    center = new_point[0:2]\n","    return center\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3FNhhHGKyvH7","executionInfo":{"status":"ok","timestamp":1613220455178,"user_tz":-60,"elapsed":121653,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}}},"source":["import tensorflow as tf\n","def _pairwise_distances(embeddings, squared=False):\n","    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n","\n","    Args:\n","        embeddings: tensor of shape (batch_size, embed_dim)\n","        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n","                 If false, output is the pairwise euclidean distance matrix.\n","\n","    Returns:\n","        pairwise_distances: tensor of shape (batch_size, batch_size)\n","    \"\"\"\n","    # Get the dot product between all embeddings\n","    # shape (batch_size, batch_size)\n","    im_embeddings = embeddings[:, :int(embeddings.shape[1] / 2)]\n","    #im_embeggings_np = im_embeddings.numpy()\n","    anchor_emb = embeddings[:, int(embeddings.shape[1] / 2):]\n","    anchor_emb = tf.expand_dims(anchor_emb[0], axis=0)\n","    #anchor_emb_np = anchor_emb.numpy()\n","    dot_product = tf.matmul(im_embeddings, tf.transpose(anchor_emb))\n","    #dot_product_np = dot_product.numpy()\n","    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n","    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n","    # shape (batch_size,)\n","    square_norm_a = tf.reduce_sum(tf.square(im_embeddings), axis=1, keepdims=True)\n","    #square_norm_a_np = square_norm_a.numpy()\n","    square_norm_b = tf.reduce_sum(tf.square(anchor_emb), axis=1, keepdims=True)\n","    #square_norm_b_np = square_norm_b.numpy()\n","    # Compute the pairwise distance matrix as we have:\n","    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n","    # shape (batch_size, batch_size)\n","    distances = tf.add(square_norm_a, square_norm_b - 2.0*dot_product)\n","\n","    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n","    distances = tf.maximum(distances, 0.0)\n","\n","    if not squared:\n","        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n","        # we need to add a small epsilon where distances == 0.0\n","        mask = tf.cast(tf.equal(distances, 0.0), float)\n","        distances = distances + mask * 1e-16\n","\n","        distances = tf.sqrt(distances)\n","\n","        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n","        distances = distances * (1.0 - mask)\n","    #distances_np = distances.numpy()\n","    return distances\n","\n","def batch_hard_triplet_loss(y_true, y_pred):\n","    \"\"\"Build the triplet loss over a batch of embeddings.\n","\n","    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n","\n","    Args:\n","        labels: labels of the batch, of size (batch_size,)\n","        embeddings: tensor of shape (batch_size, embed_dim)\n","        margin: margin for triplet loss\n","        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n","                 If false, output is the pairwise euclidean distance matrix.\n","\n","    Returns:\n","        triplet_loss: scalar tensor containing the triplet loss\n","    \"\"\"\n","    # Get the pairwise distance matrix\n","    \n","    #margin = 1.\n","    labels = y_true\n","    squared=False\n","    labels = tf.cast(labels, dtype='int32')\n","    #label_np = labels.numpy()\n","    embeddings = y_pred\n","\n","    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n","    #pairwise_dist_np = pairwise_dist.numpy()\n","    # For each anchor, get the hardest positive\n","    # First, we need to get a mask for every valid positive (they should have same label)\n","    #mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n","    #mask_anchor_positive = tf.cast(mask_anchor_positive, float)\n","\n","    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n","    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n","    #anchor_positive_dist_np=anchor_positive_dist.numpy()\n","    # shape (batch_size, 1)\n","    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=0)\n","\n","    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n","\n","    # For each anchor, get the hardest negative\n","    # First, we need to get a mask for every valid negative (they should have different labels)\n","    #mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n","    #mask_anchor_negative = tf.cast(mask_anchor_negative, float)\n","\n","    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n","    #max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n","    anchor_negative_dist = tf.multiply(1-(tf.cast(labels, float)), pairwise_dist)\n","    #anchor_negative_dist_np = anchor_negative_dist.numpy()\n","    # shape (batch_size,)\n","    zero = tf.constant(0, dtype=tf.float32)\n","    where = tf.not_equal(anchor_negative_dist, zero)\n","    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n","    D = hardest_positive_dist - hardest_negative_dist\n","    margin = tf.math.log(1 + tf.math.exp(D))\n","    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n","\n","    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n","    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n","\n","    # Get final mean triplet loss\n","    #triplet_loss = tf.reduce_mean(triplet_loss)\n","\n","    return triplet_loss\n","\n","\n","def compute_accuracy(y_true, y_pred):   \n","    \n","\n","    labels = y_true\n","    squared = False\n","    labels = tf.cast(labels, dtype='int32')\n","    margin = 1.\n","    embeddings = y_pred\n","\n","    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n","\n","    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n","    anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n","    zero = tf.constant(0, dtype=tf.float32)\n","    where = tf.not_equal(anchor_positive_dist, zero)\n","    positive_non_zero = anchor_positive_dist[where]\n","    # shape (batch_size, 1)\n","\n","    # For each anchor, get the hardest negative\n","    # First, we need to get a mask for every valid negative (they should have different labels)\n","\n","    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n","\n","    anchor_negative_dist = tf.multiply(1 - (tf.cast(labels, float)), pairwise_dist)\n","\n","    # shape (batch_size,)\n","    zero = tf.constant(0, dtype=tf.float32)\n","    where = tf.not_equal(anchor_negative_dist, zero)\n","    hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n","\n","    positive_less_negative = tf.less_equal(positive_non_zero, hardest_negative_dist - margin)\n","    positive_less_negative = tf.cast(positive_less_negative, float)\n","    accuracy = tf.reduce_mean(positive_less_negative)\n","    return accuracy\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVg7LHRKvzGL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613220455742,"user_tz":-60,"elapsed":122213,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}},"outputId":"2bbf8518-c3ad-4655-a8c7-31049e2ca397"},"source":["import os\n","from keras.models import load_model\n","from keras.utils import plot_model\n","from keras import backend as T\n","import math\n"," \n","model_folder='./gdrive/My Drive/thesis/first_model'\n","result_folder='./gdrive/My Drive/thesis/results'\n","template_dic={\n","    0:'best_model_triplet_cross_transfer.hdf5',\n","    1:'best_model_triplet_face_transfer.hdf5',\n","    2:'best_model_triplet_rail_transfer.hdf5',\n","    3:'best_model_triplet_rombo_transfer.hdf5',\n","    4:'best_model_triplet_rett_diag_transfer.hdf5',\n","    5:'best_model_triplet_rect_transfer.hdf5',\n","    6:'best_model_triplet_cross_vert_transfer.hdf5'\n","}\n"," \n"," \n","class Grid():\n","    def __init__(self, coords):\n","        self.x = coords[0] \n","        self.y = coords[1] \n","        self.w = np.abs(coords[0] - coords[2])\n","        self.h = np.abs(coords[1] - coords[3])\n","        pad = 50\n","        step = 10\n","        row =  np.arange(self.x-pad, self.x+pad+1, step=step, dtype=int)\n","        column = np.arange(self.y-pad, self.y+pad+1, step=step, dtype=int)\n","        self.grid = np.transpose([np.tile(row, len(column)), np.repeat(column, len(row))])\n","        pad_a = 10\n","        self.actions = [\n","            lambda x, y, w, h: (x, y, w + pad_a, h),\n","            lambda x, y, w, h: (x, y, w, h + pad_a),\n","            lambda x, y, w, h: (x, y - pad_a, w, h),\n","            lambda x, y, w, h: (x - pad_a, y, w, h),\n","            lambda x, y, w, h: (x - pad_a, y - pad_a, w + pad_a, h + pad_a),\n","            lambda x, y, w, h: (x - pad_a, y, w + pad_a, h + pad_a),\n","            lambda x, y, w, h: (x, y - pad_a, w + pad_a, h + pad_a),\n","            lambda x, y, w, h: (x, y, w + pad_a, h + pad_a),\n","        ]\n","        \n","\n","    \n","    def visualize(self, image, model, input_shape, template, idx, name):               \n","        min_val = np.inf\n","        save_min = False\n","        for i in range(len(self.grid)):                     \n","            x, y = self.grid[i]\n","            x = max(0, x)\n","            y = max(0, y)\n","            ROI = image[y:y + self.h, x:x + self.w]\n","            threshed =  np.array(extract_drawing(ROI))\n","            input_img = background_thumbnail(threshed, 'L', (input_shape[0], input_shape[1]))\n","            \n","            input_img = input_img.astype('float32')\n","            input_img /= 255\n","            input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)            \n","            #plt.imshow(input_img[:,:,0], cmap='gray')            \n","            #plt.show()\n","            #print(input_img.shape)\n","            #print(template.shape)\n","            #inp = np.array([[input_img], [template]])\n","            #print(inp.shape)\n","            \n","            result = model.predict([[input_img], [template]])\n","            embeddings = result\n","            result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n","            if result < min_val:\n","                min_val = result\n","                save_min = True\n","                min_y = y\n","                min_x = x\n","                min_input = input_img\n","                #min_bbox = bbox\n","            #if i in values:\n","              #print('done percent {} of template {}'.format(10*np.where(values == i)[0][0], idx))\n","        \n","        done = False\n","        min_w = self.w\n","        min_h = self.h\n","        min_x2 = min_x\n","        min_y2 = min_y\n","        iteraction = 0\n","        while not done and iteraction < 5:\n","          found_min = False\n","          for action in self.actions:\n","              (x, y, w, h) = action(min_x, min_y, min_w, min_h)\n","              ROI = image[y:y + h, x:x + w]\n","              threshed = np.array(extract_drawing(ROI))\n","              input_img = background_thumbnail(threshed, 'L',\n","                                          (input_shape[0], input_shape[1]))\n","              input_img = input_img.astype('float32')\n","              input_img /= 255\n","              input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)\n","              #plt.imshow(input_img[:,:,0], cmap='gray')\n","              #plt.show()\n","              result = model.predict([[input_img], [template]])\n","              embeddings = result\n","              result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n","              if result < min_val:\n","                  min_val = result\n","                  min_x2 = x\n","                  min_y2 = y\n","                  min_w = w\n","                  min_h = h\n","                  min_input = input_img\n","                  found_min = True\n","          if found_min:\n","            min_x = min_x2\n","            min_y = min_y2\n","            w = min_w\n","            h = min_h\n","          else:\n","            done = True\n","          iteraction += 1\n","          print('done iteration {}'.format(iteraction))\n","        \n","        #print(min_bbox)\n","        clone2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","        cv2.rectangle(clone2, (min_x2, min_y2), (min_x2 + min_w, min_y2 + min_h), color=(255, 0, 0))        \n","        cv2.putText(clone2, str(min_val), (x + 20, y + 80), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n","          color=(0, 0, 255))                \n","        cv2.rectangle(clone2, (self.x, self.y), (self.x+self.w, self.y+self.h), color=(0,0,255))\n","        #cv2.rectangle(clone2, (min_x+min_bbox[0], min_y+min_bbox[1]), (min_x+min_bbox[0]+min_bbox[2], min_y+min_bbox[1]+min_bbox[3]), color=(0,255,0))\n","        #plt.imshow(cv2.cvtColor(clone2, cv2.COLOR_BGR2RGB))\n","        #plt.show() \n","        #plt.close('all')           \n","        cv2.imwrite(os.path.join(result_folder, name, 'minimum_'+str(idx)+'.png'), clone2)\n","        fig, ax = plt.subplots(nrows=1, ncols=2)\n","        ax.ravel()[0].imshow(min_input[:,:,0], cmap='gray')\n","        ax.ravel()[1].imshow(template[:,:,0], cmap='gray')\n","        plt.savefig(os.path.join(result_folder, name, 'input_'+str(idx)+'.png'))\n","        #plt.show()\n","        plt.close('all')    \n","        print('done template {}'.format(idx))    \n","        return min_val, math.hypot(int(min_x2-min_w/2-(self.x-self.w/2)), int(min_y2-min_h/2-(self.y-self.h/2))), (min_x2, min_y2, min_w, min_h)\n","      \n","class Visualization():\n","    def __init__(self, name, image, points, templates, shape, writer):\n","        self.img = image\n","        self.name = name\n","        self.grids=[]\n","        for point in points.values():\n","            self.grids.append(Grid(point))\n","        self.templates = templates\n","        self.input_shape = shape\n","        self.scores=[]\n","        self.distances=[]\n","        self.rects=[]\n","        self.writer = writer\n","  \n"," \n","    def run(self):\n","        if not os.path.isdir(os.path.join(result_folder, self.name)):\n","            os.makedirs(os.path.join(result_folder, self.name))\n","        for i in range(len(self.templates)):\n","                   \n","            #template = np.reshape(self.templates[i], self.input_shape)\n","            template = self.templates[i]\n","            template =  np.repeat(template[..., np.newaxis], 3, -1)\n","            self.model = load_model(os.path.join(model_folder, template_dic[i]), custom_objects={'batch_hard_triplet_loss': batch_hard_triplet_loss,\n","                                                                                         'compute_accuracy_hard': compute_accuracy})               \n","            #plot_model(self.model, show_shapes=True)\n","            max_val, distance, rect = self.grids[i].visualize(self.img, self.model, self.input_shape, template, i, self.name)\n","            self.scores.append(max_val)\n","            self.distances.append(distance)\n","            self.rects.append(rect)\n","            T.clear_session()\n","            del self.model          \n","            \n","        self.writer.writerow({'names':self.name, 'scores': self.scores, 'distances':self.distances, 'rect':self.rects})"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"419xM1dlWT8d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613232068385,"user_tz":-60,"elapsed":8983911,"user":{"displayName":"Baratz96","photoUrl":"","userId":"03433220595139113760"}},"outputId":"8919d213-0788-44f9-9af2-7194ce2dec6d"},"source":["import pandas as pd\n","import csv\n","import copy\n","import gc\n","import time\n"," \n","root='./gdrive/My Drive/thesis' #modificare se cartella rinominata\n","label_dict={\n","    'cross.png':0,\n","    'face.png':1,\n","    'rail.png':2,\n","    'rombo.png':3,\n","    'rett_diag.png':4,\n","    'rect.png':5,\n","    'cross_vert.png':6\n","}\n","or_points = {\n","    \"cross\":[324,119,378,373],\n","    \"face\":[742, 287, 829, 373],\n","    \"rail\":[617, 383, 847, 534],\n","    \"rhomb\":[852, 229, 531],\n","    \"rett_diag\":[379, 300, 502, 456],\n","    \"rect\":[360, 525, 510, 680],\n","    \"cross_vert\":[502, 540, 810, 661]\n","}\n","scale_percent = 100\n","pad = 0\n"," \n","def unique_color(img):\n","    mask = img>0\n","    only_color = img[mask]\n","    colors, count = np.unique(only_color, return_counts=True)\n","    max_color = colors[count.argmax()]\n","    print(max_color)\n","    img[np.logical_not(mask)] = max_color\n","    return img\n"," \n","input_shape = (100,100,1)\n","template_folder=os.path.join(root, 'templates')\n","templates = np.zeros((7,input_shape[0], input_shape[1]))\n","for img in os.listdir(template_folder):\n","    if img != 'template.png':\n","        template = background_thumbnail(cv2.imread(os.path.join(template_folder, img),\n","                                                          cv2.IMREAD_GRAYSCALE), 'L', (input_shape[0], input_shape[1]))        \n","        template = template.astype('float32')\n","        template /= 255\n","        templates[label_dict[img]] = template\n","hom_folder = os.path.join(root, 'new_sample')\n","file_j = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).set_index('name')\n","img_list = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).loc[:, 'name'].values\n","\n"," \n","if not os.path.isdir(os.path.join(root, 'results')):\n","    os.makedirs(os.path.join(root, 'results'))\n","fieldnames = ['names', 'scores', 'distances', 'rect']\n","if not os.path.isfile(os.path.join(root, 'results', 'scores.csv')):\n","  with open(os.path.join(root, 'results', 'scores.csv'), \"w\") as f:\n","            f.write(','.join(fieldnames)+'\\n')\n"," \n","folders = pd.read_csv(os.path.join(root, 'results', 'scores.csv'), header=0, usecols=['names']).values.squeeze()\n","print(folders)\n","count = 1\n","total_time = 0\n","for image in os.listdir(hom_folder):\n","  if image.endswith('.png'):\n","    print(\"image{} of {}\".format(count, len(os.listdir(hom_folder))))\n","    #homography = cv2.imread(os.path.join(hom_folder, 'APR2018_GR270418130633-064.png'))   \n","    #if image[:-4] not in folders:\n","    start_time = time.time()\n","    print(image)\n","    homography = unique_color(cv2.imread(os.path.join(hom_folder, image), cv2.IMREAD_GRAYSCALE))\n","    #homography = unique_color(homography)\n","    or_points2 = copy.deepcopy(or_points)      \n","    points = np.array(file_j.loc[image[:-4]].to_numpy()[0])\n","    if points.shape ==(1,):\n","      points = np.array(points[0])\n","    print(points.shape)\n","    points = [tuple(x) for x in points]\n","    print(points)\n","    r_points = computeHomographyRhomb(homography, points)\n","    or_points2['rhomb'].insert(2, r_points[0])\n","    homography = cv2.medianBlur(homography, 3)\n","    width = int(homography.shape[1] * scale_percent / 100)\n","    height = int(homography.shape[0] * scale_percent / 100)\n","    homography = cv2.resize(homography, (width, height), interpolation=cv2.INTER_AREA)\n","    for x,y in or_points2.items():\n","        or_points2[x] = np.array([int(p*(scale_percent/100)) for p in y])\n","        or_points2[x][0:2]-=pad\n","        or_points2[x][2:]+=pad\n","        or_points2[x] = or_points2[x].tolist()\n","  \n","    csv_file = open(os.path.join(root, 'results', 'scores.csv'), mode='a')\n","    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    app = Visualization(image[:-4], homography, or_points2, templates, input_shape, writer)\n","    #app = Visualization('APR2018_GR270418130633-064', homography, or_points, templates, input_shape, writer)\n","    app.run()      \n","    csv_file.close()\n","    del app\n","    print(gc.collect())\n","    end_time = time.time()\n","    loop_time = (end_time - start_time) / 60\n","    total_time += loop_time\n","    print('loop time: {}m'.format(loop_time))\n","    print('total_time: {}m'.format(total_time))\n","  count +=1"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[]\n","image1 of 30\n","Immagini-03.png\n","255\n","(5, 2)\n","[(390, 1495), (1035, 1475), (1300, 1620), (1060, 1905), (390, 1930)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 7.2436822334925335m\n","total_time: 7.2436822334925335m\n","image2 of 30\n","Immagini-05.png\n","255\n","(5, 2)\n","[(325, 1495), (925, 1480), (1175, 1680), (935, 1845), (310, 1895)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609917\n","loop time: 7.028451641400655m\n","total_time: 14.27213387489319m\n","image3 of 30\n","Immagini-11.png\n","255\n","(5, 2)\n","[(475, 1440), (1050, 1455), (1240, 1635), (1065, 1785), (480, 1810)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done iteration 5\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.891067628065745m\n","total_time: 21.163201502958934m\n","image4 of 30\n","Immagini-13.png\n","255\n","(5, 2)\n","[(440, 1465), (975, 1440), (1170, 1545), (1010, 1715), (475, 1755)]\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609917\n","loop time: 6.76331885655721m\n","total_time: 27.926520359516143m\n","image5 of 30\n","Immagini-17.png\n","255\n","(5, 2)\n","[(450, 1475), (1080, 1485), (1350, 1665), (1120, 1935), (445, 1925)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609924\n","loop time: 6.953708851337433m\n","total_time: 34.88022921085358m\n","image6 of 30\n","Immagini-23.png\n","255\n","(5, 2)\n","[(565, 1470), (1090, 1450), (1320, 1590), (1090, 1750), (585, 1760)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.839117109775543m\n","total_time: 41.71934632062912m\n","image7 of 30\n","Immagini-31.png\n","255\n","(5, 2)\n","[(325, 1285), (945, 1265), (1240, 1470), (1010, 1745), (335, 1775)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.664468797047933m\n","total_time: 48.38381511767705m\n","image8 of 30\n","Immagini-35.png\n","255\n","(5, 2)\n","[(480, 1415), (1045, 1420), (1240, 1575), (1050, 1815), (490, 1830)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.880750087896983m\n","total_time: 55.26456520557404m\n","image9 of 30\n","Immagini-37.png\n","255\n","(5, 2)\n","[(420, 1485), (1005, 1470), (1245, 1660), (1010, 1875), (420, 1900)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.925385665893555m\n","total_time: 62.189950871467595m\n","image10 of 30\n","Immagini-39.png\n","255\n","(5, 2)\n","[(410, 1540), (1025, 1510), (1230, 1710), (1025, 1885), (405, 1915)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609939\n","loop time: 6.74203439950943m\n","total_time: 68.93198527097702m\n","image11 of 30\n","Immagini-41.png\n","255\n","(5, 2)\n","[(395, 1350), (1050, 1330), (1355, 1580), (1070, 1850), (410, 1905)]\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.938472906748454m\n","total_time: 75.87045817772548m\n","image12 of 30\n","Immagini-43.png\n","255\n","(5, 2)\n","[(420, 1340), (1060, 1330), (1355, 1550), (1085, 1815), (405, 1860)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.8307748715082806m\n","total_time: 82.70123304923376m\n","image13 of 30\n","Immagini-45.png\n","255\n","(5, 2)\n","[(350, 1440), (1040, 1455), (1250, 1750), (1045, 1850), (355, 1905)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.9063167850176495m\n","total_time: 89.60754983425142m\n","image14 of 30\n","Immagini-49.png\n","255\n","(5, 2)\n","[(305, 1390), (920, 1385), (1230, 1620), (910, 1910), (280, 1930)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609913\n","loop time: 6.7822376648585m\n","total_time: 96.38978749910991m\n","image15 of 30\n","Immagini-53.png\n","255\n","(5, 2)\n","[(395, 1530), (1045, 1545), (1295, 1770), (1045, 2000), (395, 2015)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.635957705974579m\n","total_time: 103.02574520508449m\n","image16 of 30\n","Immagini-55.png\n","255\n","(5, 2)\n","[(365, 1335), (965, 1305), (1265, 1535), (1055, 1745), (365, 1780)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.968867643674215m\n","total_time: 109.9946128487587m\n","image17 of 30\n","Immagini-59.png\n","255\n","(5, 2)\n","[(405, 1380), (1035, 1380), (1410, 1695), (1020, 1985), (410, 2020)]\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.931033710638682m\n","total_time: 116.92564655939739m\n","image18 of 30\n","Immagini-01.png\n","255\n","(5, 2)\n","[(365, 1455), (935, 1430), (1215, 1595), (940, 1840), (380, 1895)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.88687489827474m\n","total_time: 123.81252145767213m\n","image20 of 30\n","Immagini-07.png\n","255\n","(5, 2)\n","[(340, 1395), (980, 1385), (1365, 1620), (970, 1850), (330, 1855)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done iteration 4\n","done iteration 5\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609966\n","loop time: 7.117101792494456m\n","total_time: 130.9296232501666m\n","image21 of 30\n","Immagini-09.png\n","255\n","(5, 2)\n","[(330, 1325), (1010, 1325), (1235, 1570), (975, 1760), (300, 1750)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609950\n","loop time: 6.876351459821065m\n","total_time: 137.80597470998765m\n","image22 of 30\n","Immagini-15.png\n","255\n","(5, 2)\n","[(430, 1295), (1020, 1290), (1295, 1515), (1035, 1690), (400, 1725)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.785397477944692m\n","total_time: 144.59137218793234m\n","image23 of 30\n","Immagini-19.png\n","255\n","(5, 2)\n","[(415, 1370), (965, 1340), (1265, 1555), (970, 1720), (420, 1765)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609913\n","loop time: 6.931887074311574m\n","total_time: 151.5232592622439m\n","image24 of 30\n","Immagini-25.png\n","255\n","(5, 2)\n","[(420, 1360), (945, 1360), (1155, 1475), (975, 1760), (415, 1810)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.987355629603068m\n","total_time: 158.51061489184696m\n","image25 of 30\n","Immagini-27.png\n","255\n","(5, 2)\n","[(395, 1395), (960, 1380), (1120, 1525), (945, 1775), (390, 1780)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609966\n","loop time: 6.719696203867595m\n","total_time: 165.23031109571454m\n","image26 of 30\n","Immagini-29.png\n","255\n","(5, 2)\n","[(305, 1415), (965, 1435), (1265, 1670), (950, 1990), (320, 1975)]\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done iteration 2\n","done template 2\n","done iteration 1\n","done iteration 2\n","done iteration 3\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done iteration 2\n","done template 6\n","609917\n","loop time: 7.079368376731873m\n","total_time: 172.30967947244642m\n","image27 of 30\n","Immagini-33.png\n","255\n","(5, 2)\n","[(385, 1410), (1030, 1365), (1240, 1610), (1015, 1795), (365, 1795)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done iteration 2\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done iteration 2\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.914362112681071m\n","total_time: 179.22404158512748m\n","image28 of 30\n","Immagini-47.png\n","255\n","(5, 2)\n","[(205, 1385), (1015, 1370), (1255, 1550), (1000, 1795), (165, 2000)]\n","done iteration 1\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done iteration 2\n","done template 3\n","done iteration 1\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609949\n","loop time: 6.677060465017955m\n","total_time: 185.90110205014543m\n","image29 of 30\n","Immagini-51.png\n","255\n","(5, 2)\n","[(495, 1490), (1225, 1465), (1515, 1750), (1190, 1920), (520, 1990)]\n","done iteration 1\n","done iteration 2\n","done template 0\n","done iteration 1\n","done template 1\n","done iteration 1\n","done template 2\n","done iteration 1\n","done template 3\n","done iteration 1\n","done iteration 2\n","done template 4\n","done iteration 1\n","done template 5\n","done iteration 1\n","done template 6\n","609913\n","loop time: 6.876144448916118m\n","total_time: 192.77724649906153m\n"],"name":"stdout"}]}]}