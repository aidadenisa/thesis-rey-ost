{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wojXqpbzAMdD"
   },
   "source": [
    "In questo notebook le reti neurali vengono utilizzate per trovare e analizzare i pattern piÃ¹ complessi. Basta eseguire Runtime->esegui tutte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1613220334480,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "oQNamwhVsrbd",
    "outputId": "886112dd-e4e1-4cf8-935a-59af0e4ba002"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sng4-l9sAfUf"
   },
   "source": [
    "IMPORTANTE: queste versioni non vanno cambiate. Versioni successive di Tensorflow non fanno girare il codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118414,
     "status": "ok",
     "timestamp": 1613220451924,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "otMuOedo8nnQ",
    "outputId": "cb678c37-e5ca-4df5-c427-909f0e4960e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: q in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (2.6)\n",
      "Requirement already satisfied: keras==2.3.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (1.20.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (1.6.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from keras==2.3.1) (5.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aida\\appdata\\roaming\\python\\python37\\site-packages (from keras==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: q in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (2.6)\n",
      "Collecting tensorflow==2.2.0\n",
      "  Using cached tensorflow-2.2.0-cp37-cp37m-win_amd64.whl (459.2 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aida\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (1.20.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (3.14.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Using cached tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (1.36.1)\n",
      "Collecting scipy==1.4.1\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9 MB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (0.12.0)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Using cached tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.30.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.16.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\aida\\anaconda3\\envs\\rocf_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, scipy, astunparse, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.0\n",
      "    Uninstalling tensorboard-2.4.0:\n",
      "      Successfully uninstalled tensorboard-2.4.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.1.0\n",
      "    Uninstalling tensorflow-2.1.0:\n",
      "      Successfully uninstalled tensorflow-2.1.0\n",
      "Successfully installed astunparse-1.6.3 scipy-1.4.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install q keras==2.3.1\n",
    "!pip install q tensorflow==2.2.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 118415,
     "status": "ok",
     "timestamp": 1613220451929,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "HJHVz2mYvGla"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def background_thumbnail(template, modality, thumbnail_size=(200,200)):\n",
    "    foreground = Image.fromarray(template).convert(modality)\n",
    "    background = Image.new(modality, thumbnail_size, \"white\")\n",
    "    foreground.thumbnail(thumbnail_size)\n",
    "    (w, h) = foreground.size\n",
    "    upper_left=(int((thumbnail_size[0] - w) / 2), int((thumbnail_size[1] - h) / 2))\n",
    "    background.paste(foreground, upper_left)\n",
    "    return np.array(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 119333,
     "status": "ok",
     "timestamp": 1613220452852,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "kir95NDuvfuY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def maxDeviationThresh(hist):\n",
    "    maximum = max(hist)\n",
    "    index_max = list(hist).index(maximum)\n",
    "    index_min = 0\n",
    "    for i in range(0, index_max):\n",
    "        if not hist[i] and hist[i+1]:\n",
    "            index_min = i\n",
    "            break\n",
    "    \n",
    "    distances = []\n",
    "    x1 = index_min\n",
    "    y1 = hist[index_min]\n",
    "    x2 = index_max\n",
    "    y2 = hist[index_max]\n",
    "    for i in range(index_min + 1, index_max):\n",
    "        x0 = i\n",
    "        y0 = hist[i]\n",
    "        distance = np.abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1) / np.sqrt(\n",
    "            (y2 - y1) ** 2 + (x2 - x1) ** 2)\n",
    "        distances.append(distance)\n",
    "    if index_min < index_max - 1:\n",
    "      T_index = distances.index(max(distances))\n",
    "    else:\n",
    "      T_index = -index_min\n",
    "    return T_index + index_min\n",
    "\n",
    "\n",
    "def extract_drawing(img):\n",
    "  dst = cv2.bilateralFilter(img, 10, sigmaColor=15, sigmaSpace=15)\n",
    "  #dst = img.copy()\n",
    "  #max_occ = np.bincount(dst[dst > 0]).argmax()\n",
    "  #dst[dst == 0] = max_occ\n",
    "  threshed = np.ones(dst.shape, np.uint8) * 255\n",
    "  if np.any(dst < 255):\n",
    "      hist, _ = np.histogram(dst[dst < 255].flatten(), range(257))\n",
    "      thresh_val = maxDeviationThresh(hist)\n",
    "      mask = dst < thresh_val\n",
    "      threshed[mask] = 0\n",
    "  return threshed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 119332,
     "status": "ok",
     "timestamp": 1613220452855,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "Nj8w1vciviWS"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "p_dst = [(382, 219),(852, 219), (852, 537), (382, 537)]\n",
    "def computeHomographyRhomb(image, points):\n",
    "    img = image.copy()\n",
    "    point_rhomb = points[2] + (1,)\n",
    "    mask = np.ones(5, dtype=int)\n",
    "    mask[2] = 0\n",
    "    right_points = np.array(points)[np.ma.make_mask(mask)]\n",
    "    hm, status = cv2.findHomography(np.array(right_points), np.array(p_dst))\n",
    "    new_point = np.dot(hm, point_rhomb)\n",
    "    new_point = tuple(np.round(new_point/new_point[2]).astype(int))\n",
    "    center = new_point[0:2]\n",
    "    return center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 121653,
     "status": "ok",
     "timestamp": 1613220455178,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "3FNhhHGKyvH7"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# def _pairwise_distances(embeddings, squared=False):\n",
    "#     \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "\n",
    "#     Args:\n",
    "#         embeddings: tensor of shape (batch_size, embed_dim)\n",
    "#         squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "#                  If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "#     Returns:\n",
    "#         pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "#     \"\"\"\n",
    "#     # Get the dot product between all embeddings\n",
    "#     # shape (batch_size, batch_size)\n",
    "#     im_embeddings = embeddings[:, :int(embeddings.shape[1] / 2)]\n",
    "#     #im_embeggings_np = im_embeddings.numpy()\n",
    "#     anchor_emb = embeddings[:, int(embeddings.shape[1] / 2):]\n",
    "#     anchor_emb = tf.expand_dims(anchor_emb[0], axis=0)\n",
    "#     #anchor_emb_np = anchor_emb.numpy()\n",
    "#     dot_product = tf.matmul(im_embeddings, tf.transpose(anchor_emb))\n",
    "#     #dot_product_np = dot_product.numpy()\n",
    "#     # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "#     # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "#     # shape (batch_size,)\n",
    "#     square_norm_a = tf.reduce_sum(tf.square(im_embeddings), axis=1, keepdims=True)\n",
    "#     #square_norm_a_np = square_norm_a.numpy()\n",
    "#     square_norm_b = tf.reduce_sum(tf.square(anchor_emb), axis=1, keepdims=True)\n",
    "#     #square_norm_b_np = square_norm_b.numpy()\n",
    "#     # Compute the pairwise distance matrix as we have:\n",
    "#     # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "#     # shape (batch_size, batch_size)\n",
    "#     distances = tf.add(square_norm_a, square_norm_b - 2.0*dot_product)\n",
    "\n",
    "#     # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "#     distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "#     if not squared:\n",
    "#         # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "#         # we need to add a small epsilon where distances == 0.0\n",
    "#         mask = tf.cast(tf.equal(distances, 0.0), float)\n",
    "#         distances = distances + mask * 1e-16\n",
    "\n",
    "#         distances = tf.sqrt(distances)\n",
    "\n",
    "#         # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "#         distances = distances * (1.0 - mask)\n",
    "#     #distances_np = distances.numpy()\n",
    "#     return distances\n",
    "\n",
    "# def batch_hard_triplet_loss(y_true, y_pred):\n",
    "#     \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "\n",
    "#     For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "\n",
    "#     Args:\n",
    "#         labels: labels of the batch, of size (batch_size,)\n",
    "#         embeddings: tensor of shape (batch_size, embed_dim)\n",
    "#         margin: margin for triplet loss\n",
    "#         squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "#                  If false, output is the pairwise euclidean distance matrix.\n",
    "\n",
    "#     Returns:\n",
    "#         triplet_loss: scalar tensor containing the triplet loss\n",
    "#     \"\"\"\n",
    "#     # Get the pairwise distance matrix\n",
    "    \n",
    "#     #margin = 1.\n",
    "#     labels = y_true\n",
    "#     squared=False\n",
    "#     labels = tf.cast(labels, dtype='int32')\n",
    "#     #label_np = labels.numpy()\n",
    "#     embeddings = y_pred\n",
    "\n",
    "#     pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "#     #pairwise_dist_np = pairwise_dist.numpy()\n",
    "#     # For each anchor, get the hardest positive\n",
    "#     # First, we need to get a mask for every valid positive (they should have same label)\n",
    "#     #mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "#     #mask_anchor_positive = tf.cast(mask_anchor_positive, float)\n",
    "\n",
    "#     # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "#     anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "#     #anchor_positive_dist_np=anchor_positive_dist.numpy()\n",
    "#     # shape (batch_size, 1)\n",
    "#     hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=0)\n",
    "\n",
    "#     tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "#     # For each anchor, get the hardest negative\n",
    "#     # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "#     #mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "#     #mask_anchor_negative = tf.cast(mask_anchor_negative, float)\n",
    "\n",
    "#     # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "#     #max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "#     anchor_negative_dist = tf.multiply(1-(tf.cast(labels, float)), pairwise_dist)\n",
    "#     #anchor_negative_dist_np = anchor_negative_dist.numpy()\n",
    "#     # shape (batch_size,)\n",
    "#     zero = tf.constant(0, dtype=tf.float32)\n",
    "#     where = tf.not_equal(anchor_negative_dist, zero)\n",
    "#     hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "#     D = hardest_positive_dist - hardest_negative_dist\n",
    "#     margin = tf.math.log(1 + tf.math.exp(D))\n",
    "#     tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "#     # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "#     triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "#     # Get final mean triplet loss\n",
    "#     #triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "#     return triplet_loss\n",
    "\n",
    "\n",
    "# def compute_accuracy(y_true, y_pred):   \n",
    "    \n",
    "\n",
    "#     labels = y_true\n",
    "#     squared = False\n",
    "#     labels = tf.cast(labels, dtype='int32')\n",
    "#     margin = 1.\n",
    "#     embeddings = y_pred\n",
    "\n",
    "#     pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "#     # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "#     anchor_positive_dist = tf.multiply(tf.cast(labels, float), pairwise_dist)\n",
    "#     zero = tf.constant(0, dtype=tf.float32)\n",
    "#     where = tf.not_equal(anchor_positive_dist, zero)\n",
    "#     positive_non_zero = anchor_positive_dist[where]\n",
    "#     # shape (batch_size, 1)\n",
    "\n",
    "#     # For each anchor, get the hardest negative\n",
    "#     # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "\n",
    "#     # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "\n",
    "#     anchor_negative_dist = tf.multiply(1 - (tf.cast(labels, float)), pairwise_dist)\n",
    "\n",
    "#     # shape (batch_size,)\n",
    "#     zero = tf.constant(0, dtype=tf.float32)\n",
    "#     where = tf.not_equal(anchor_negative_dist, zero)\n",
    "#     hardest_negative_dist = tf.reduce_min(anchor_negative_dist[where], axis=0)\n",
    "\n",
    "#     positive_less_negative = tf.less_equal(positive_non_zero, hardest_negative_dist - margin)\n",
    "#     positive_less_negative = tf.cast(positive_less_negative, float)\n",
    "#     accuracy = tf.reduce_mean(positive_less_negative)\n",
    "#     return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rocf_env'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CONDA_DEFAULT_ENV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as T\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root='../' #modificare se cartella rinominata\n",
    "\n",
    "model_folder=root + 'first_model'\n",
    "result_folder=root + 'results'\n",
    "template_dic={\n",
    "    0:'best_model_triplet_cross_transfer.hdf5',\n",
    "    1:'best_model_triplet_face_transfer.hdf5',\n",
    "    2:'best_model_triplet_rail_transfer.hdf5',\n",
    "    3:'best_model_triplet_rombo_transfer.hdf5',\n",
    "    4:'best_model_triplet_rett_diag_transfer.hdf5',\n",
    "    5:'best_model_triplet_rect_transfer.hdf5',\n",
    "    6:'best_model_triplet_cross_vert_transfer.hdf5'\n",
    "}\n",
    "\n",
    "model_folder\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122213,
     "status": "ok",
     "timestamp": 1613220455742,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "tVg7LHRKvzGL",
    "outputId": "2bbf8518-c3ad-4655-a8c7-31049e2ca397"
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "class Grid():\n",
    "    def __init__(self, coords):\n",
    "        self.x = coords[0] \n",
    "        self.y = coords[1] \n",
    "        self.w = np.abs(coords[0] - coords[2])\n",
    "        self.h = np.abs(coords[1] - coords[3])\n",
    "        pad = 50\n",
    "        step = 10\n",
    "        row =  np.arange(self.x-pad, self.x+pad+1, step=step, dtype=int)\n",
    "        column = np.arange(self.y-pad, self.y+pad+1, step=step, dtype=int)\n",
    "        self.grid = np.transpose([np.tile(row, len(column)), np.repeat(column, len(row))])\n",
    "        pad_a = 10\n",
    "        self.actions = [\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h),\n",
    "            lambda x, y, w, h: (x, y, w, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w, h),\n",
    "            lambda x, y, w, h: (x - pad_a, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x - pad_a, y, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y - pad_a, w + pad_a, h + pad_a),\n",
    "            lambda x, y, w, h: (x, y, w + pad_a, h + pad_a),\n",
    "        ]\n",
    "        \n",
    "\n",
    "    \n",
    "    def visualize(self, image, model, input_shape, template, idx, name):               \n",
    "        min_val = np.inf\n",
    "        save_min = False\n",
    "        for i in range(len(self.grid)):                     \n",
    "            x, y = self.grid[i]\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            ROI = image[y:y + self.h, x:x + self.w]\n",
    "            threshed =  np.array(extract_drawing(ROI))\n",
    "            input_img = background_thumbnail(threshed, 'L', (input_shape[0], input_shape[1]))\n",
    "            \n",
    "            input_img = input_img.astype('float32')\n",
    "            input_img /= 255\n",
    "            input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)            \n",
    "            #plt.imshow(input_img[:,:,0], cmap='gray')            \n",
    "            #plt.show()\n",
    "            #print(input_img.shape)\n",
    "            #print(template.shape)\n",
    "            #inp = np.array([[input_img], [template]])\n",
    "            #print(inp.shape)\n",
    "            \n",
    "            result = model.predict([[input_img], [template]])\n",
    "            embeddings = result\n",
    "            result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n",
    "            if result < min_val:\n",
    "                min_val = result\n",
    "                save_min = True\n",
    "                min_y = y\n",
    "                min_x = x\n",
    "                min_input = input_img\n",
    "                #min_bbox = bbox\n",
    "            #if i in values:\n",
    "              #print('done percent {} of template {}'.format(10*np.where(values == i)[0][0], idx))\n",
    "        \n",
    "        done = False\n",
    "        min_w = self.w\n",
    "        min_h = self.h\n",
    "        min_x2 = min_x\n",
    "        min_y2 = min_y\n",
    "        iteraction = 0\n",
    "        while not done and iteraction < 5:\n",
    "          found_min = False\n",
    "          for action in self.actions:\n",
    "              (x, y, w, h) = action(min_x, min_y, min_w, min_h)\n",
    "              ROI = image[y:y + h, x:x + w]\n",
    "              threshed = np.array(extract_drawing(ROI))\n",
    "              input_img = background_thumbnail(threshed, 'L',\n",
    "                                          (input_shape[0], input_shape[1]))\n",
    "              input_img = input_img.astype('float32')\n",
    "              input_img /= 255\n",
    "              input_img =  np.repeat(input_img[..., np.newaxis], 3, -1)\n",
    "              #plt.imshow(input_img[:,:,0], cmap='gray')\n",
    "              #plt.show()\n",
    "              result = model.predict([[input_img], [template]])\n",
    "              embeddings = result\n",
    "              result = _pairwise_distances(embeddings, squared=False).numpy()[0, 0]\n",
    "              if result < min_val:\n",
    "                  min_val = result\n",
    "                  min_x2 = x\n",
    "                  min_y2 = y\n",
    "                  min_w = w\n",
    "                  min_h = h\n",
    "                  min_input = input_img\n",
    "                  found_min = True\n",
    "          if found_min:\n",
    "            min_x = min_x2\n",
    "            min_y = min_y2\n",
    "            w = min_w\n",
    "            h = min_h\n",
    "          else:\n",
    "            done = True\n",
    "          iteraction += 1\n",
    "          print('done iteration {}'.format(iteraction))\n",
    "        \n",
    "        #print(min_bbox)\n",
    "        clone2 = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.rectangle(clone2, (min_x2, min_y2), (min_x2 + min_w, min_y2 + min_h), color=(255, 0, 0))        \n",
    "        cv2.putText(clone2, str(min_val), (x + 20, y + 80), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,\n",
    "          color=(0, 0, 255))                \n",
    "        cv2.rectangle(clone2, (self.x, self.y), (self.x+self.w, self.y+self.h), color=(0,0,255))\n",
    "        #cv2.rectangle(clone2, (min_x+min_bbox[0], min_y+min_bbox[1]), (min_x+min_bbox[0]+min_bbox[2], min_y+min_bbox[1]+min_bbox[3]), color=(0,255,0))\n",
    "        #plt.imshow(cv2.cvtColor(clone2, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show() \n",
    "        #plt.close('all')           \n",
    "        cv2.imwrite(os.path.join(result_folder, name, 'minimum_'+str(idx)+'.png'), clone2)\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        ax.ravel()[0].imshow(min_input[:,:,0], cmap='gray')\n",
    "        ax.ravel()[1].imshow(template[:,:,0], cmap='gray')\n",
    "        plt.savefig(os.path.join(result_folder, name, 'input_'+str(idx)+'.png'))\n",
    "        #plt.show()\n",
    "        plt.close('all')    \n",
    "        print('done template {}'.format(idx))    \n",
    "        return min_val, math.hypot(int(min_x2-min_w/2-(self.x-self.w/2)), int(min_y2-min_h/2-(self.y-self.h/2))), (min_x2, min_y2, min_w, min_h)\n",
    "      \n",
    "class Visualization():\n",
    "    def __init__(self, name, image, points, templates, shape, writer):\n",
    "        self.img = image\n",
    "        self.name = name\n",
    "        self.grids=[]\n",
    "        for point in points.values():\n",
    "            self.grids.append(Grid(point))\n",
    "        self.templates = templates\n",
    "        self.input_shape = shape\n",
    "        self.scores=[]\n",
    "        self.distances=[]\n",
    "        self.rects=[]\n",
    "        self.writer = writer\n",
    "  \n",
    " \n",
    "    def run(self):\n",
    "        if not os.path.isdir(os.path.join(result_folder, self.name)):\n",
    "            os.makedirs(os.path.join(result_folder, self.name))\n",
    "        for i in range(len(self.templates)):\n",
    "                   \n",
    "            #template = np.reshape(self.templates[i], self.input_shape)\n",
    "            template = self.templates[i]\n",
    "            template =  np.repeat(template[..., np.newaxis], 3, -1)\n",
    "            self.model = load_model(os.path.join(model_folder, template_dic[i]), custom_objects={'batch_hard_triplet_loss': batch_hard_triplet_loss,\n",
    "                                                                                         'compute_accuracy_hard': compute_accuracy})               \n",
    "            #plot_model(self.model, show_shapes=True)\n",
    "            max_val, distance, rect = self.grids[i].visualize(self.img, self.model, self.input_shape, template, i, self.name)\n",
    "            self.scores.append(max_val)\n",
    "            self.distances.append(distance)\n",
    "            self.rects.append(rect)\n",
    "            T.clear_session()\n",
    "            del self.model          \n",
    "            \n",
    "        self.writer.writerow({'names':self.name, 'scores': self.scores, 'distances':self.distances, 'rect':self.rects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8983911,
     "status": "ok",
     "timestamp": 1613232068385,
     "user": {
      "displayName": "Baratz96",
      "photoUrl": "",
      "userId": "03433220595139113760"
     },
     "user_tz": -60
    },
    "id": "419xM1dlWT8d",
    "outputId": "8919d213-0788-44f9-9af2-7194ce2dec6d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    " \n",
    "# root='./gdrive/My Drive/thesis' #modificare se cartella rinominata\n",
    "\n",
    "label_dict={\n",
    "    'cross.png':0,\n",
    "    'face.png':1,\n",
    "    'rail.png':2,\n",
    "    'rombo.png':3,\n",
    "    'rett_diag.png':4,\n",
    "    'rect.png':5,\n",
    "    'cross_vert.png':6\n",
    "}\n",
    "or_points = {\n",
    "    \"cross\":[324,119,378,373],\n",
    "    \"face\":[742, 287, 829, 373],\n",
    "    \"rail\":[617, 383, 847, 534],\n",
    "    \"rhomb\":[852, 229, 531],\n",
    "    \"rett_diag\":[379, 300, 502, 456],\n",
    "    \"rect\":[360, 525, 510, 680],\n",
    "    \"cross_vert\":[502, 540, 810, 661]\n",
    "}\n",
    "scale_percent = 100\n",
    "pad = 0\n",
    " \n",
    "def unique_color(img):\n",
    "    mask = img>0\n",
    "    only_color = img[mask]\n",
    "    colors, count = np.unique(only_color, return_counts=True)\n",
    "    max_color = colors[count.argmax()]\n",
    "    print(max_color)\n",
    "    img[np.logical_not(mask)] = max_color\n",
    "    return img\n",
    " \n",
    "input_shape = (100,100,1)\n",
    "template_folder=os.path.join(root, 'templates')\n",
    "templates = np.zeros((7,input_shape[0], input_shape[1]))\n",
    "for img in os.listdir(template_folder):\n",
    "    if img != 'template.png':\n",
    "        template = background_thumbnail(cv2.imread(os.path.join(template_folder, img),\n",
    "                                                          cv2.IMREAD_GRAYSCALE), 'L', (input_shape[0], input_shape[1]))        \n",
    "        template = template.astype('float32')\n",
    "        template /= 255\n",
    "        templates[label_dict[img]] = template\n",
    "hom_folder = os.path.join(root, 'new_sample')\n",
    "file_j = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).set_index('name')\n",
    "img_list = pd.read_json(os.path.join(hom_folder, 'points.txt'), lines=True).loc[:, 'name'].values\n",
    "\n",
    " \n",
    "if not os.path.isdir(os.path.join(root, 'results')):\n",
    "    os.makedirs(os.path.join(root, 'results'))\n",
    "fieldnames = ['names', 'scores', 'distances', 'rect']\n",
    "if not os.path.isfile(os.path.join(root, 'results', 'scores.csv')):\n",
    "  with open(os.path.join(root, 'results', 'scores.csv'), \"w\") as f:\n",
    "            f.write(','.join(fieldnames)+'\\n')\n",
    " \n",
    "folders = pd.read_csv(os.path.join(root, 'results', 'scores.csv'), header=0, usecols=['names']).values.squeeze()\n",
    "print(folders)\n",
    "count = 1\n",
    "total_time = 0\n",
    "for image in os.listdir(hom_folder):\n",
    "  if image.endswith('.png'):\n",
    "    print(\"image{} of {}\".format(count, len(os.listdir(hom_folder))))\n",
    "    #homography = cv2.imread(os.path.join(hom_folder, 'APR2018_GR270418130633-064.png'))   \n",
    "    #if image[:-4] not in folders:\n",
    "    start_time = time.time()\n",
    "    print(image)\n",
    "    homography = unique_color(cv2.imread(os.path.join(hom_folder, image), cv2.IMREAD_GRAYSCALE))\n",
    "    #homography = unique_color(homography)\n",
    "    or_points2 = copy.deepcopy(or_points)      \n",
    "    points = np.array(file_j.loc[image[:-4]].to_numpy()[0])\n",
    "    if points.shape ==(1,):\n",
    "      points = np.array(points[0])\n",
    "    print(points.shape)\n",
    "    points = [tuple(x) for x in points]\n",
    "    print(points)\n",
    "    r_points = computeHomographyRhomb(homography, points)\n",
    "    or_points2['rhomb'].insert(2, r_points[0])\n",
    "    homography = cv2.medianBlur(homography, 3)\n",
    "    width = int(homography.shape[1] * scale_percent / 100)\n",
    "    height = int(homography.shape[0] * scale_percent / 100)\n",
    "    homography = cv2.resize(homography, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    for x,y in or_points2.items():\n",
    "        or_points2[x] = np.array([int(p*(scale_percent/100)) for p in y])\n",
    "        or_points2[x][0:2]-=pad\n",
    "        or_points2[x][2:]+=pad\n",
    "        or_points2[x] = or_points2[x].tolist()\n",
    "  \n",
    "    csv_file = open(os.path.join(root, 'results', 'scores.csv'), mode='a')\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    app = Visualization(image[:-4], homography, or_points2, templates, input_shape, writer)\n",
    "    #app = Visualization('APR2018_GR270418130633-064', homography, or_points, templates, input_shape, writer)\n",
    "    app.run()      \n",
    "    csv_file.close()\n",
    "    del app\n",
    "    print(gc.collect())\n",
    "    end_time = time.time()\n",
    "    loop_time = (end_time - start_time) / 60\n",
    "    total_time += loop_time\n",
    "    print('loop time: {}m'.format(loop_time))\n",
    "    print('total_time: {}m'.format(total_time))\n",
    "  count +=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUMmlDPg/I4jxSt7s+biqV",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "test_on_homog.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b3dfd9d6ca873100d039dca19450565cda26e5cd96cbe6db5eff130d83a403f8"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
